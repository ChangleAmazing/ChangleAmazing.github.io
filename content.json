[{"title":"百度分布式 ID 生成器","date":"2020-02-03T02:18:47.000Z","path":"2020/02/03/分布式 id 生成器/","text":"分布式 ID 生成器是分布式项目开发中的常用工具，弄懂其原理对理解分布式有一定的帮助。 绝大多数公司使用的分布式 ID 生成器都是依赖于雪花算法（snowflake）实现的。 snowflake snowflake 如上图所示，雪花算法生成 id 为 64 位二进制串，由几个部分组成： 1 位标识位，默认为 0，因为二进制首位为符号位，一般生成的 id 都要求是正数，所以固定为 0 41 位时间戳，可以表示的时间为 69 年 10 位工作机器 id，记录工作机器 id。可以部署在 $2^{10}$ (1024) 个节点上，包括 5 位 datacenterId 和 5 位 workerId 12 位自增序列。记录同一时间戳内产生的不同 id，支持的序号为$2^{12}$（4096）个 这样的设计可以保证所有生成的 id 按照时间趋势递增，并且不会产生重复的 id，也可以根据实际节点数扩展或缩减工作机器 id 部分的位数。 雪花算法的主要缺点是时钟回拨问题。 时钟回拨是指服务器时间因为某些原因导致时间回退。可能导致时钟回拨的原因有多种，比如服务器使用了本地时间，然后服务器校时服务修正了系统时间。 这样会导致生成一个已经使用过的 ID。 百度 UidGenerator百度的 UidGenerator 也是基于 snowflake 来实现的，不过调整了生成的 id 中的组成部分顺序。 UIDGenerator 如上图所示，UidGenerator 生成的 64 位二进制串主要包括以下几个部分： sign：1 位，与 snowflake 一致，固定为 1，即生成的 UID 为正数 delta seconds：28 位，时间戳，相对于时间基点 2016-05-20 的增量值，单位：秒，最多可支持约 8.7 年 worker id：22位，机器 id，每次机器启动（包括重启）时由数据库（MySQL 内置 WorkerID 分配器）分配（也可以自定义实现）。 sequence：13位，同一个时间戳的并发序列，可以支持$2^{13}$ (8192) 个并发。 UidGenerator 有两种实现方式：DefaultUidGenerator 和 CachedUidGenerator。 DefaultUIDGeneratordelta seconds这个值是当前时间与 epoch时间的时间差，单位为秒。epoch 时间默认为 2016-09-20，需要将它配置为生成分布式 ID 服务上线的时间。 worker idworker id 是在机器启动时通过 MySQL 的内置 WorkerID 分配器分配的。UidGenerator 会在生成分布式 ID 的实例启动的时候，向数据库的表中插入一行数据，数据的 ID 值就是 workerId 的值。由于 workerId 默认为 22 位，所以所有实例重启次数不超过 $2^{22} - 1$ 次。 sequence生成 sequence 部分的代码通过 synchronized 关键字保证线程安全，通过简单的异常处理来避免时钟回拨问题。 1234567891011121314151617protected synchronized long nextId() &#123; long currentSecond = getCurrentSecond(); if (currentSecond &lt; lastSecond) &#123; long refusedSeconds = lastSecond - currentSecond; throw new UidGenerateException(\"Clock moved backwards. Refusing for %d seconds\", refusedSeconds); &#125; if (currentSecond == lastSecond) &#123; sequence = (sequence + 1) &amp; bitsAllocator.getMaxSequence(); if (sequence == 0) &#123; currentSecond = getNextSecond(lastSecond); &#125; &#125; else &#123; sequence = 0L; &#125; lastSecond = currentSecond; return bitsAllocator.allocate(currentSecond - epochSeconds, workerId, sequence);&#125; 如果当前时间与上一次生成 id 时间为同一个时间戳，则增加 sequence。如果 sequence 自增值超过 $，就会通过自旋等待下一秒，而不是直接抛出异常。 如果当前时间是新的一秒，那么将 sequence 置为 0，重新开始分配该秒对应的 id。 CachedUIDGeneratorCachedUidGenerator 是 UidGenerator 的重要改进实现。它利用了 RingBuffer（与 disruptor 一致)。 RingBufferRingBuffer 本质上是一个数组，数组中的每个项被称为 slot。CachedUidGenerator 设计了两个 RingBuffer，一个用来保存唯一 ID，一个保存 flag。 每个 RingBuffer 容量为 SnowFlake 算法中 sequence 部分最大值，且为 $2^{n}$，对于 UidGenerator 默认设计来说，即为 $2^{13}$。 UID-RingBuffer 中 Tail 与 Cursor 指针用来读写 slot。其中，Tail 指针表示 Producer 生成的最大序号（此序号从 0 开始，持续递增）。Cursor 指针表示 Consumer 消费到的最小序号。 这两个指针不能超过对方。若 Cursor 指针超过 Tail，则说明消费了还未生产序号，所以当 Cursor 赶上 Tail 时，应该通过 RejectedTakeBufferHandler 指定 TakeRejectPolicy。 若 Tail 指针超过 Cursor 指针，则说明生产者覆盖了还未消费的 slot。所以当 Tail 赶上 Cursor 时，应该通过 RejectedPutBufferHandler 指定 PutRejectPolicy。 Flag-Ringbuffer 用来记录每个 slot 的状态（是否可填充、是否可消费）。 由于数组元素在内存中是连续分配的，这样可以最大程度利用 Cpu Cache 提升性能，但是会带来 伪共享 问题。 为了解决该问题，Uid-Generator 在 Tail、Cursor、Flag-RingBuffer 中采用 CacheLine 补齐方式。 FalseSharing 这里的说明可以看 RingBuffer 中补齐问题 。 RingBuffer 填充时机RingBuffer 共有三种填充方式 初始化预填充 RingBuffer 初始化时，预先填充整个 RingBuffer。 即时填充 消费 slot 时，即时检查剩余可以消费的 slot（tail - cursor)。如果小于设定阈值，则填充空余 slots。 周期填充 通过 Schedule 线程，定时补全空闲 slots。 上面分析了 CachedUidGenerator 依赖的数据结构，下面分析它的实现。实际上它继承了 DefaultUidGenerator，所以它是对 DefaultUidGenerator 的增强。 初始化CachedUidGenerator 在初始化时会给 workerId 赋值，方式与 DefaultUidGenerator 一致。还会初始化 RingBuffer，这个过程包括的操作有： 根据 boostPower 确定 RingBuffer 的 size 构造 RingBuffer，默认 paddingFactor 为 50。即当 RingBuffer 中剩余可用 ID 数量少于 50% 时，就触发一个异步线程往 RingBuffer 中填充新的 ID，直到填满为止 判断是否配置了 scheduleInterval 属性值，这个值表示检查填充的周期。默认不配置 初始化 Put 操作拒绝策略，对应属性 rejectedPutBufferHandler。即当 RingBuffer 已满，无法继续填充时的操作策略。默认情况下会丢弃Put 操作，记录日志。如果有需求，可以自定义实现 RejectedPutBufferHandler 接口 初始化 Take 操作拒绝策略，对应属性 rejectedTakeBufferHandler。即 RingBuffer 中没有可以使用的 ID 时的操作策略。默认情况下会记录日志并抛出 UidGenerateException 异常。如果有需求，可以自定义实现 RejectedTakeBufferHandler 接口 初始化填满 RingBuffer 中所有 slot 开启 buffer 补丁线程（需配置 scheduleInterval ） 第二步中的异步线程实现是 UidGenerator 解决时钟回拨的关键。在满足填充新的 ID 条件时，通过时间值递增得到新的时间值，而不是获取当前时间。 取值RingBuffer 初始化之后，就是取值过程了： 如果剩余可用 ID 百分比低于 paddingFactor 参数指定值，就会异步生成若干个 ID 集合，直到将 RingBuffer 填满。 如果获取值的位置追上了 tail&#39; 指针，就会执行 Task 操作的拒绝策略。 获取 slot 中的分布式 ID。 将该 slot 对应的 flag 设置为 CAN_PUT_FLAG。 总结绝大多数分布式 ID 生成器都是基于 SnowFlake 来实现的，而 SnowFlake 也有一些缺点。 本文中提到 Uid-Generator 通过自增列、RingBuffer 以及时间递增的措施解决了 SnowFlake 的传统问题。 这其中也涉及到一些计算机底层原理，关于该部分知识的解析会在其它文章中继续分析。","tags":[{"name":"Snowflake","slug":"Snowflake","permalink":"http://changleamazing.com/tags/Snowflake/"},{"name":"IDGenerator","slug":"IDGenerator","permalink":"http://changleamazing.com/tags/IDGenerator/"}]},{"title":"Redis 数据持久化","date":"2020-01-01T18:02:32.000Z","path":"2020/01/02/Redis 数据持久化/","text":"Redis 是一种内存型数据库，一旦服务器进程退出，数据库的数据就会丢失。为了解决这个问题，Redis 提供了 RDB 持久化、AOF 持久化、RDB-AOF 混合持久化等多种持久化方式，将内存中的数据保存到磁盘中，避免数据的丢失。 RDB 持久化RDB 持久化是 Redis 默认的持久化方式。 RDB 持久化会创建一个经过压缩的以 .rdb 结尾的二进制文件，其中包含了服务器在各个数据库中存储的键值对数据等信息。 RDB 文件创建创建 RDB文件有多种方式。用户可以使用 SAVE 或者 BGSAVE 命令手动创建 RDB 文件，也可以通过配置 save 配置项使服务器在满足指定条件时自动执行 BGSAVE 命令。 SAVE用户可以通过 SAVE 命令让 Redis 服务器以同步方式创建 RDB 文件。 SAVE 是无参数命令，如下： 12redis&gt; SAVEOK 在 SAVE 命令执行期间， Redis 服务器将阻塞，直到 RDB 文件创建完毕。 当执行 SAVE 命令时，如果本地已经存在相应的 RDB 文件，则会在新的 RDB 文件创建完成之后删除原有的 RDB 文件。 SAVE 命令的复杂度为 O(N)， N 表示 Redis 服务器所有数据库包含的键值对的总数。 BGSAVE因为 SAVE 命令是同步操作，会阻塞服务器，导致执行此命令期间 Redis 无法执行其它命令。所以 Redis 提供了 SAVE 命令的异步版本 — BGSAVE。BGSAVE 会使用子进程创建 RDB 文件。 BGSAVE 也是无参数命令： 12redis&gt; BGSAVEOK 虽然 BGSAVE 的异步操作不会使服务器在创建 RDB 文件过程中阻塞，但是创建子进程的过程会造成短时间的阻塞。 父进程调用操作系统 fork 函数创建一个子进程，而 fork 函数在父进程占用内存越大时，创建子进程耗时越长。 BGSAVE 命令的复杂度为 O(N)， N 表示 Redis 服务器所有数据库包含的键值对的总数。 配置自动创建 RDB 文件除了通过 SAVE 与 BGSAVE 命令手动创建 RDB 文件外，还可以通过在配置文件中配置 save 选项，让服务器在满足指定条件时自动执行 BGSAVE 命令。 save 配置项选项如下： 1save &lt;seconds&gt; &lt;changes&gt; seconds 参数指定触发持久化操作的周期，changes 参数用来指定触发持久化操作所需要的修改次数。 1save 60 10000 这个配置表示服务器在 60s 内至少执行了 10000 次修改时，服务器会自动执行 BGSAVE 命令。 Redis 默认持久化方式为 RDB，如果不改变默认配置，那么 Redis 使用的 save 选项为： 123save 60 10000save 300 100save 3600 1 这里配置了多个 save 选项，当其中任意一个条件被满足时就会触发服务器执行 BGSAVE 命令。 为了避免由于同时使用多个 RDB 文件创建方式或者配置多个 save 选项导致服务器频繁创建 RDB 文件，Redis 服务器在每次成功创建 RDB 文件后，会将负责自动触发 BGSAVE 命令的时间计数器以及修改次数计数器清零并重新开始计数。 SAVE 与 BGSAVE 的选择由于 SAVE 命令会阻塞 Redis 服务器向其它客户端服务，所以如果我们需要创建 RDB 文件时同时为其它客户端服务，就只能使用 BGSAVE 命令创建 RDB 文件。 而 SAVE 命令更适合维护离线 Redis 服务器，因为它不会创建子进程而消耗额外的内存。 RDB 优缺点RDB 持久化可以生成紧凑的 RDB 文件，并且使用 RDB 文件恢复数据也很快. 但是无论是 SAVE 命令还是 BGSAVE 命令，当服务器停机时，服务器丢失的数据量取决于创建 RDB 文件的时间间隔：间隔越长，丢失数据越多。如果提高执行 SAVE 或者 BGSAVE 命令的频率，会导致 Redis 服务器性能骤降，甚至低于传统关系型数据库。 所以 RDB 持久化更像是一种备份手段而不是一种常规数据持久化方案。 AOF 持久化RDB 持久化是全量式操作，而 AOF 是增量操作。 服务器每次执行完写命令之后，都会以协议文本的方式将被执行的写命令追加到 AOF 文件的结尾。在服务器停机之后，只需要重新执行 AOF 文件中保存的 Redis 命令，就可以将数据库恢复至停机之前的状态。 AOF 文件中唯一不是用户执行的命令是 SELECT，这是服务器根据用户正在使用的数据库号码自动加上的。 同步命令到 AOF 文件的整个过程可以分为三个阶段： 命令传播：Redis 将执行完的命令、命令的参数、命令的参数个数等信息发送到 AOF 程序中。 缓存追加：AOF 程序根据接收到的命令数据，将命令转换为网络通讯协议的格式，然后将协议内容追加到服务器的 AOF 缓存中。 文件写入和保存：AOF 缓存中的内容被写入到 AOF 文件末尾，如果设定的 AOF 保存条件被满足的话， fsync 函数或者 fdatasync 函数会被调用，将写入的内容真正地保存到磁盘中。 由于默认持久化方式为 RDB，所以用户需要配置 appendonly 选项来打开 AOF 持久化功能： 1appendonly yes 打开 AOF 持久化功能之后，Redis 在默认情况下会创建一个名为 appendonly.aof 的文件作为 AOF 文件。 AOF 文件冲洗频率 为了提高程序的写入性能，现代化的操作系统通常会把针对硬盘的多次写操作优化成一次写操作。当程序调用 write 系统调用对文件进行写入时，系统会先将数据写入位于内存的缓冲区中，当到达指定的时限或者满足某些写入条件时，系统才会调用 fsync 或者 fdatasync 函数，将缓冲区数据冲洗至硬盘。 上述机制虽然能提高写入性能，但是对于持久化功能来说，两次执行冲洗操作的间隔会影响持久化的安全性。 Redis 提供了 appendfsync 选项来控制系统冲洗 AOF 文件的频率。 1appendfsync always|everysec|no appendfsync 有三个可选值，分别代表的意义如下： always：每执行一个写命令，就对 AOF 文件执行一次冲洗操作 everysec：每隔 1s，就对 AOF 文件执行一次冲洗操作 no：不主动对 AOF 文件执行冲洗操作，由操作系统决定何时对 AOF 进行冲洗。 对于这三种冲洗策略来说，不同的安全性对应着不同的性能： always：最多只会丢失一个命令的数据，但是由于对磁盘的频繁写入，导致 Redis 服务器性能骤降至关系型数据库的水平 everysec：最多丢失 1s 之内产生的命令数据，这是一种兼顾性能与安全性的折中方案 no：最多丢失服务器最后一次冲洗 AOF 文件之后产生的所有命令数据，数据量的大小取决于系统冲洗 AOF 文件的频率，不安全 对比之下，Redis 选择 everysec 作为默认的冲洗策略，除非有明确的需求，否则也不应该修改该选项值。 AOF 重写由于 AOF 的增量特性，AOF 文件会越来越大，其中也会存在一些对相同键执行过的多次修改操作，导致有一部分命令是冗余的。 例如： 12345SELECT 0SET msg &quot;hello world!&quot;SET msg &quot;good bye&quot; 实际上，上述三条命令可以直接将第二条去掉，执行后最终效果与原来是一致的。这种冗余命令的存在增加了 AOF 文件的体积，恢复数据时耗费时间也越多。 为了减少冗余命令，Redis 提供了 AOF 重写功能，该功能会能够生成一个全新的 AOF 文件，其中只包含恢复当前数据库所需要的尽可能少的命令。 对于上面的三条命令来说，AOF 重写之后就会变成如下所示： 123SELECT 0SET msg &quot;good bye&quot; AOF 重写操作可以通过执行 BGREWRITEAOF 命令或者配置选项来触发。 BGREWRITEAOFBGREWRITEAOF 是一个无命令参数： 12redis&gt; BGREWRITEAOFBackground append only file rewriting started 复杂度为 O(N),N 表示服务器所有数据库包含的键值对总数。 BGREWRITEAOF 是一个异步命令，Redis 服务器接收到该命令之后会创建一个子进程来扫描数据库并生成新的 AOF 文件。当新的 AOF 文件生成完毕，子进程就会退出并通知 Redis，Redis 就会使用新的 AOF 文件代替原有 AOF 文件。 如果发送 BGREWRITEAOF 请求时，服务器正在创建 RDB 文件，那么服务器会将 AOF 重写操作延后到 RDB 文件创建完毕之后再执行，避免两个写操作同时执行导致服务器性能下降。 如果服务器在执行重写操作的过程中，又收到了新的 BGREWRITEAOF 命令，那么会返回以下错误： 12redis&gt; BGREWRITEAOF(error) ERR Background append only file rewriting already in progress AOF 重写配置选项以下两个配置选项可以设置 Redis 触发 BGREWRITEAOF 命令的条件： 12auto-aof-rewrite-min-size &lt;value&gt;auto-aof-rewirte-percentage &lt;value&gt; auto-aof-rewrite-min-size 选项用于设置触发 AOF 重写所需要的最小 AOF 文件体积。 例如对于该选项默认值来说： 1auto-aof-rewrite-min-size 64mb 当 AOF 文件体积小于 64mb 时，服务器不会自动执行 BGREWRITEAOF 命令。 auto-aof-rewirte-percentage 选项配置的值是触发 AOF 重写所需要的文件体积增大比例。 例如对于该选项默认值来说： 1auto-aof-rewirte-percentage 100 表示当前 AOF 文件体积比最后一次 AOF 文件重写之后的体积增大一倍时，会触发 BGREWRITEAOF 命令。 如果 Redis 还没有执行过 AOF 文件重写操作，那就会把启动服务器时使用的 AOF 文件体积当做最后一次 AOF 文件重写的体积。 假设 AOF 文件上次重写之后体积为 300MB，当前 AOF 文件达到 600MB 时,才会触发 AOF 重写操作。 AOF 持久化优缺点AOF 持久化的安全性是 RDB 望尘莫及的，正常情况下配置 appendonly everysec 可以将数据丢失的时间压缩至 1s 以内。 当然，AOF 也有相应的缺点： AOF 使用协议文本来存储操作,所以文件体积相对于包含相同数据的 RDB 文件来说会大得多，生成 AOF 文件所需的时间也比生成 RDB 文件时间更长 AOF 持久化需要通过执行 AOF 文件中保存的命令来恢复数据库，所以 AOF 持久化数据恢复速度比 RDB 文件恢复慢很多，并且数据库体积越大，差距越明显 AOF 使用的 BGREWRITEAOF 命令也需要创建子进程，如果数据库体积较大，进行 AOF 文件重写会占用大量资源，并导致服务器短暂阻塞。 RDB-AOF 混合持久化由于 RDB 持久化与 AOF 持久化都有各自优缺点，用户也较难抉择。 Redis4.0 开始，引入了 RDB-AOF 混合持久化模式，这种模式基于 AOF 持久化模式构建。所以需要用户打开 AOF 持久化功能，并且配置 1aof-use-rdb-preamble yes 此后，当 Redis 执行 AOF 重写操作时，会根据数据库当前的状态生成出对应的 RDB 数据，并且将这部分数据写入新建的 AOF 文件当中，而在此之后执行的写操作，会以协议文本的方式追加到新的 AOF 文件末尾（即 RDB 数据后）。 当支持 RDB-AOF 混合持久化模式的 Redis 服务器启动并载入 AOF 文件时，首先会检查 AOF 文件头部是否包含 RDB 格式的内容。如果包含，那服务器就会先载入 RDB 数据，之后再载入 AOF 数据。 RDB-AOF 混合持久化综合了 RDB 持久化与 AOF 持久化的优点。既可以通过 AOF 文件中的 RDB 数据快速恢复数据，又可以通过 AOF 包含的 AOF 数据将丢失数据的时间压缩至 1s 之内。 Redis 现在已发布 5.0 版本，默认是没有打开 RDB-AOF 混合持久化功能的。不过 Redis 作者声称该持久化方式之后会取代 RDB 持久化成为 Redis 默认持久化方式。","tags":[{"name":"Redis 持久化","slug":"Redis-持久化","permalink":"http://changleamazing.com/tags/Redis-%E6%8C%81%E4%B9%85%E5%8C%96/"}]},{"title":"HashMap 源码解析","date":"2019-12-11T16:52:50.000Z","path":"2019/12/12/HashMap/","text":"本文基于 JDK8 源码深入分析 HashMap 的结构与重要操作，并梳理一些面试中的常见问题。 类结构 成员变量DEFAULT_INITIAL_CAPACITY1static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; HashMap 中槽数量的默认值，即 HashMap 中 table 数组的 table.length; HashMap 初始化时，如果未指定 capacity 时，即设定 capacity 为此值。 MAXIMUM_CAPACITY1static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; HashMap 中槽数量的最大值。 HashMap 初始化时，如果指定的 capacity 大于该值，则将 capacity 设置为该值。 table1transient Node&lt;K,V&gt;[] table; HashMap 中装载数据的桶的数组。table.length 在分配数据之后长度总是 2 的幂。（除了在自举机制中一些操作允许长度为 0） entrySet1transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; 装载了所有键值对的集合，在遍历 HashMap 时一般使用这个集合，比使用 keySet 集合遍历速度大约快 1 倍。 size1transient int size; HashMap 中目前存放的键值对的个数。 modCount1transient int modCount; HashMap 结构更改的次数（即增删操作的次数）。用于在遍历时保证fail-fast 机制生效。 thresholdHashMap 中存放键值对的阈值，当 size &gt; threshold 时，会触发 table 数组扩容操作。 table 数组没有被分配数据时，threshold 值等于 0 或者是 table.length。而在 table 数组被分配数据之后，它的值等于 table.length * loadFactor。 loadFactor装载因子：即负载率；默认为 0.75。 JDK 1.7 中提到， As a general rule, the default load factor (.75) offers a good tradeoff between time and space costs. Higher values decrease the space overhead but increase the lookup cost (reflected in most of the operations of the HashMap class, including get and put). The expected number of entries in the map and its load factor should be taken into account when setting its initial capacity, so as to minimize the number of rehash operations. If the initial capacity is greater than the maximum number of entries divided by the load factor, no rehash operations will ever occur. 意思是 0.75 在时间和空间上提供了很好的折中。由于 threshold = capacity * loadFactor ，如果 loadFactor 设置过高，可以节省少量空间，但是会导致 threshold 和 capacity 非常接近， Hash 碰撞 的概率增大，一定程度上提高了 put 和 get 操作的耗时；如果 loadFactor 设置过低，则会产生相反的效果。 TREEIFY_THRESHOLD1static final int TREEIFY_THRESHOLD = 8; table数组中的每个槽中存储的数据量，在 大于 该值时，槽中存储数据的数据结构会变为红黑树。 ### UNTREEIFY_THRESHOLD 1static final int UNTREEIFY_THRESHOLD = 6; table`数组中的每个槽中存储的数据量，在 小于 该值时，槽中存储数据的数据结构会变为链表。 构造方法public HashMap()123public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted&#125; 最常用的构造方法。 loadFactor 为默认值 0.75 ; public HashMap(int initialCapacity)123public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; 调用 public HashMap(int initialCapacity, float loadFactor); 手动设置 HashMap 的初始化容量。 loadFactor 为默认值 0.75 ; public HashMap(int initialCapacity, float loadFactor)123456789101112public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125; loadFactor 为自定义值 ; static final int tableSizeFor(int cap)123456789101112/** * Returns a power of two size for the given target capacity. */static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 从注释可知，该方法的返回值为 2 的幂。 实际上这个算法返回的是，大于 cap 的最接近 cap 的 2 的 次幂。 该构造方法，实际上控制的是 threshold 而不是直接设置 capacity。 public HashMap(Map&lt;? extends K, ? extends V&gt; m)1234public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125; 用另一个 map 构造一个新的 hashmap。 loadFactor 为默认值。 final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict)1234567891011121314151617181920/** 若 evict 为 false,代表是在创建 hashMap 时调用了这个函数;若 evict 为true,代表是在创建 hashMap 后才调用这个函数，例如 putAll 函数。*/final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict) &#123; int s = m.size(); if (s &gt; 0) &#123; if (table == null) &#123; // pre-size float ft = ((float)s / loadFactor) + 1.0F;// 阿里推荐初始化值 int t = ((ft &lt; (float)MAXIMUM_CAPACITY) ? (int)ft : MAXIMUM_CAPACITY); if (t &gt; threshold) threshold = tableSizeFor(t); &#125; else if (s &gt; threshold) resize(); for (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123; K key = e.getKey(); V value = e.getValue(); putVal(hash(key), key, value, false, evict); &#125; &#125;&#125; 初始化时， ft = ((float)s / loadFactor) + 1.0F,即为 table.length + 1。然后调用 threshold = tableSizeFor(t)；这样 threshold 的值，是 2 * table.length。所以，新增元素不会立刻导致扩容。 查public V get(Object key)1234public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125; static final int hash(Object key)1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 该函数主要是调用了 key.hashCode( ) 方法，实际就是 Object 类中的 hashCode() 方法。作用是将对象的地址映射成一个整数值，尽量保证随机性。而 HashMap 中没有直接使用 Object 中的 hashCode() 的返回值作为 hash() 函数的结果，而是增加了 (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16) 这一步,将 hashCode() 的返回值与向右移动 16 位的 h 做异或运算。这里，(h &gt;&gt;&gt; 16) 叫做 扰动函数，该扰动函数保证了函数最后的返回值的后十六位中，是高位与低位共同运算出的结果。增加了节点在 table 数组中分布的随机性。 结果显示，当 HashMap 数组长度为 512 时，这个时候会取低 9 位的值来决定新增节点的位置。在有扰动函数的情况下，碰撞会减少 10%。 final Node&lt;K,V&gt; getNode(int hash, Object key)123456789101112131415161718192021222324final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; /* 条件判断，判断 `table` 数组不为空，且有元素存在；在该节点对应的槽里面也要有元素存在 */ if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 判断 key 是不是该槽位中的第一个元素。 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; // 如果该槽位中不止存在一个值，判断该槽位的节点是不是树节点 if ((e = first.next) != null) &#123; //如果是树节点，直接调用树查找节点的方法。并返回查找到的值 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 如果该槽位中的数据仍用链表存储。则直接遍历判断元素的 key 是不是等于要查找的 key do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null; &#125; 这是 HashMap 查找方法的主流程，相对比较简单。在进行最外层判断时，使用到了 tab[(n - 1) &amp; hash] 这段代码。tab[(n - 1) &amp; hash] 是 table.length 必须保持 2 的 次幂的关键。在得到一个元素 key 哈希运算返回值 hash 后，为了找到该元素在 table 中具体分布在哪个槽中，一般会使用 hash % table.length。当 table.length 等于 2^n 时， 存在hash % table.length = hash &amp; (table.length - 1)。这样，由于位运算更快，可以更加快速的找到每一个节点对应的槽位。 增/改public V put(K key, V value)123456789101112 /** * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or * &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;. * (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map * previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.) */public V put(K key, V value) &#123; //evict 为true,代表是在创建 hashMap 后才调用这个函数 /** onlyIfAbsent 表示是否只在没有该节点映射时，put 才生效（是否允许覆盖）。 false 表示允许覆盖操作 **/ return putVal(hash(key), key, value, false, true);&#125; 如果 HashMap 中已经存在该节点的映射（更新操作），返回值会是旧节点的 value。如果不存在该节点的映射（新增操作），返回值会是 null。所以可以用返回值来判断原来的 HashMap 中是否存在关于该节点的映射，在某些时刻很有用。 final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 如果数组没有初始化，或者长度为 0，则重新设置数组长度 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 如果该节点 key 对应的槽位没有元素，直接新建节点将该元素放入该槽位 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; /** 如果槽位的第一个元素 p 的 key 与 带插入的节点的 key 相等，则直接令 e = p，此时 e.value 被 p.value 替代，相当于更新操作 **/ if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; /** 如果槽位的元素是树节点，调用树的插入值的方法 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // 槽中元素为链表节点 else &#123; for (int binCount = 0; ; ++binCount) &#123; // 判断 p 是否为尾结点 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 判断新增节点后，是否需要更新数据结构，槽中节点数等于 8 就更新 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //如果链表中有元素的 key 等于 e.key，则更新 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 如果 e 不为 null，说明之前存在该 key 的映射， if (e != null) &#123; // existing mapping for key V oldValue = e.value; // 允许覆盖则更新节点值 if (!onlyIfAbsent || oldValue == null) e.value = value; // 为 linkedHashMap 提供的函数，将最近访问的元素置于链表尾部，保证链表有序性 afterNodeAccess(e); return oldValue; &#125; &#125; // 修改次数增加 ++modCount; // 判断是否需要扩容 if (++size &gt; threshold) resize(); // 为 linkedHashMap 提供的函数，回调删除头节点 afterNodeInsertion(evict); return null; &#125; public V putIfAbsent(K key, V value)123public V putIfAbsent(K key, V value) &#123; return putVal(hash(key), key, value, true, true); &#125; 第四个参数 onlyIfAbsent 为 true 表示只允许插入操作，更新操作不生效。 删public V remove(Object key)12345public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value; &#125; 如果返回值为空，表示 HashMap 中不存在该 key 对应的节点。否则，返回对应节点的 value。 final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; // 判断数组有元素存在且 key 对应的槽位有元素存在 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; // 如果槽中第一个元素 p 是要删除的节点，令 node = p if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; // 槽中第一个元素 p 不是要删除的节点，在后继节点中寻找 else if ((e = p.next) != null) &#123; // 槽中元素存储在 RBT 中，令 node 等于从树中查找到的节点 if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); // 槽中元素存储在链表中，令 node 等于从链表中查找到的节点 else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; // node 不为空, 且不需要匹配 value 或者成功匹配到 value，删除节点 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); // 如果要删除的节点为槽中第一个节点，则将第二个节点作为首节点 else if (node == p) tab[index] = node.next; else p.next = node.next; ++modCount; --size; afterNodeRemoval(node); return node; &#125; &#125; return null; &#125; 扩容final Node&lt;K,V&gt;[] resize()123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; //如果数组已经初始化过且 table.length != 0 if (oldCap &gt; 0) &#123; /** 如果数组原来的长度为 MAXIMUM_CAPACITY，table.length 无法扩大， 修改 threshold = Integer.MAX_VALUE 使 map 可以继续存放元素**/ if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 扩大 table.length = min(oldCap * 2 ,MAXIMUM_CAPACITY) //只有原来 oldCap.length &gt;= 16，会使阈值翻倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //原来 table.length = 0 且 threshold ！= 0 ，在带参非集合初始化时会出现这种情况。 //设置 newCap 为初始化时构造函数中 tableSizeFor() 方法返回的 threshold else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; // table.length = 0 &amp;&amp; threshold = 0 ，无参初始化时出现这种情况 // 设置 cap 和 threshold 为默认值 else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //有两种情况会符合该判断 //1. 原来的 table.length * 2 &gt;= MAXIMUM_CAPACITY， 此时将 threshold 设置为 Integer.MAX_VALUE //2. 当原来的 table.length &lt; 16 时，设置 threshold = min(MAXIMUM_CAPACITY,threshold * loadFactor)。(故意设置 loadFactor 很高时，会出现 threshold * loadFactor &gt; MAXIMUM_CAPACITY) if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;\"rawtypes\",\"unchecked\"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; // 移动元素 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; //方便 GC oldTab[j] = null; // 如果该槽中只有一个元素，新数组的槽中依然只有它一个元素 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; // 如果槽中数据结构为 RBT else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); // 如果槽中数据结构为链表 else &#123; // preserve order // Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; // 确定该节点在 resize 之后是否会改变索引值 // e.hash &amp; oldCap = 0，说明索引值在 resize 之后不会改变 if ((e.hash &amp; oldCap) == 0) &#123; //将元素放在索引为 index 的链表尾部 if (loTail == null) loHead = e; else //这里说明了 JDK8 是尾插法 loTail.next = e; loTail = e; &#125; else &#123; //将元素放在索引为 index + oldCap 的链表尾部 if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); //将链表尾结点置空 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 其中有一些很关键的点， 移动元素前会使判断 e.hash &amp; oldCap 是否等于 0。假设 oldCap 为 2^k ，元素m 的索引为 oldIndex，hash(m) 的值为 hash，存在 oldIndex= hash &amp; ( 2^k - 1 )。(2^k - 1) 的结果的二进制表达式是 k 个 1。所以 oldIndex的结果等于 hash 的二进制表达式的后 k 位的值。 扩容后，新数组的长度 newCap 为 2^(k + 1)。元素 m 在新数组中的索引 newIndex = hash &amp; (2 ^ (k + 1) - 1)。同上，newIndex 的结果等于 hash 的二进制表达式的后 k + 1 位的值。用 b 代表 hash二进制表示的第k + 1位，那么 newIndex - oldIndex 就等于 b 代表的值。 b的权值为 2^k等于 oldCap。当 b = 0时， newIndex = oldIndex；当 b = 1时，newIndex = oldIndex + oldCap。所以，元素m在新数组的位置就由hash的第 k + 1位的值确定，这个值就等于hash &amp; oldCap。 因此，我们在扩充 HashMap 的时候，不需要像 JDK1.7 的实现那样重新计算 hash 了。 另一个关键点，在于移动时，使用尾插法，保持了元素在原来槽中的相对顺序。这个方法，解决了 JDK1.7 中多线程访问 HashMap 时，resize 过程中会出现的循环链表的问题。但 HashMap 仍然不是线程安全的。 重要问题JDK8 相对于 JDK7 优化点有哪些JDK8 对于 HashMap 的改动很大。主要的优化点在： HashMap 中使用的数据结构新增红黑树，当哈希冲突严重时，查找元素的耗时也不会恶化到 O(n) 级别。 插入元素的方式。JDK8 采用了尾插法插入元素，在扩容时保持了原来元素的相对顺序。而 JDK7 采用的是头插法，多线程扩容时可能会导致产生闭环问题。 扩容时，HashMap 中元素索引直接由元素 hashcode来计算是原位置或者是原位置 + 数组长度。而在 JDK7 中，元素扩容时，都会调用 hash() 方法重新计算元素的 hashcode ，再决定元素在数组中的索引。 JDK1.7 死循环问题当多线程添加元素并且引起扩容时，可能会触发 HashMap 中某个链表死循环。主要的原因是 JDK1.7 使用的头插法，导致原来两个节点的顺序在扩容后被翻转，多线程操作时就可能引起死循环。而在 JDK1.8 中，扩容时使用的是尾插法插入元素，这样元素的相对顺序不会改变，所以不会再出现死循环的问题。 JDK8 线程安全问题JDK8 中解决了 HashMap 死循环之后，依然不是线程的。 举两个例子： 当多线程放入两个 hashcode 一致的元素时，两个元素会放入相同的槽中，当他们获取到了同一个链表尾部元素时，会将各自的元素标记为链表尾部，导致其中一个元素丢失。 当多线程放入新元素时，都会执行到 ++size 这一步，表示 HashMap 中保存的元素数量增加了，但是 size 并不是 volatile 修饰的，多线程操作时可能会导致值被覆盖，从而 size 与实际数据不对。","tags":[{"name":"HashMap","slug":"HashMap","permalink":"http://changleamazing.com/tags/HashMap/"},{"name":"Source Code","slug":"Source-Code","permalink":"http://changleamazing.com/tags/Source-Code/"}]},{"title":"Redis 分布式锁","date":"2019-11-17T16:52:50.000Z","path":"2019/11/18/分布式锁/","text":"在单节点中，需要用并发线程都能访问到的资源的状态变化来控制同步。在分布式应用中，使用应用所有节点都能访问到的 Redis 中的某个 key 来控制多节点访问。 单节点 Redis 分布式锁setnxsetnx 指令会在 key 不存在的情况下放入 redis，如果存在则不会设置。 123456&gt;setnx lock:distributed trueOK...other code...&gt;del lock:distributed 这种方式的问题在于，执行到 other code 时，程序出现异常，导致 del 指令不会被执行，key 没有被释放，这样会陷入死锁。 setnx then expire为了解决死锁，乍一看可以使用 expire 来给 key 设置超时时间。 1234567&gt;setnx lock:distributed trueOK&gt;expire lock:distributed 5...other code...&gt;del lock:distributed 这种处理其实仍然有问题，因为 setnx 与 expire 不是原子操作， 执行 expire 语句之前可能发生异常。死锁仍然会出现。 set and expire为了解决非原子性操作被中断的问题，在 Redis 2.8 中加入了 setnx 与 expire 组合在一起的原子指令。 123456&gt;set lock:distributed true ex 5 nxOK...other code...&gt;del lock:distributed 这种方式保证了加锁并设置有效时间操作的原子性，但是依然有问题。 假设我们在加锁与释放锁之间的业务代码执行时间超过了设置的有效时间，此时锁会因为超时被释放。会导致两种情况： 其他节点 B 获取锁之后，执行超时节点 A 执行完成，释放了 B 的锁。 其它节点获取到了锁，执行临界区代码时就可能会出现并发问题。 解决锁被其他线程释放问题因为在加锁时，各个节点使用的同一个 key，所以会存在超时节点释放了当前加锁节点的锁的情况。这种情况下，可以给加锁的 key 设置一个随机值，删除的时候需要判断 key 当前的 value 是不是等于随机值。 12345678910val &#x3D; Random.nextInt();if( redis.set(key,val,true,5) )&#123; ... other code ... value &#x3D; redis.get(key); if(val &#x3D;&#x3D; value)&#123; redis.delete(key); &#125;&#125; 上述代码实现了根据随机值删除的逻辑，但是获取 value 直到 delete 指令并非是原子指令，仍然可能有并发问题。这时候需要使用 lua 脚本处理，因为 lua 脚本可以保证连续多个指令原子执行。 12345if redis.call(\"get\",KEYS[1]) == ARGV[1] then return redis.call(\"del\",KEYS[1])else return 0end 这种方式可以避免锁被其他线程释放的问题。 临界区并发问题临界区代码出现并发问题的本质是业务代码执行时间大于锁过期时间。 我们可以定时刷新加锁时间，保证业务代码在锁过期时间内执行完成。 12345678910111213141516171819202122232425262728293031private volatile boolean isFlushExpiration = true;while(redis.set(lock, val, NOT_EXIST, SECONDS, 20))&#123; Thread thread = new Thread(new FlushExpirationTherad()); thread.setDeamon(true); thread.start(); ... other code ... &#125;isFlushExpiration = false;String deleteScript = \"if redis.call(\"get\",KEYS[1]) == ARGV[1] then\" + \"return redis.call(\"del\",KEYS[1])\" + \"else return 0 end\";redis.eval(deleteScript,1,key,val); private class FlushExpirationTherad implements Runnable&#123; @Override public void run()&#123; while(isFlushExpiration)&#123; String checkAndExpireScript = \"if redis.call('get', KEYS[1]) == ARGV[1] then \" + \"return redis.call('expire',KEYS[1],ARGV[2]) \" + \"else return 0 end\"; redis.eval(checkAndExpireScript,1,key,val,\"20\"); // 每隔十秒检查是否完成 Thread.sleep(10); &#125; &#125; &#125; 这种实现是用一个线程定期监控客户端是否执行完成。也可以由服务端实现心跳检测机制来保证业务完成（Zookeeper)。 所以实现单节点 Redis 分布式锁要关注三个关键问题： 获取锁与设置超时时间实现为原子操作（Redis2.8 开始已支持） 设置随机字符串保证释放锁时能保证只释放自己持有的锁（给对应的 key 设置随机值） 判断与释放锁必须实现为原子操作（lua 脚本实现） 多节点 Redis 分布式锁为了保证项目的高可用性，项目一般都配置了 Redis 集群，以防在单节点 Redis 宕机之后，所有客户端都无法获得锁。 在集群环境下，Redis 存在 failover 机制。当 Master 节点宕机之后，会开始异步的主从复制（replication），这个过程可能会出现以下情况： 客户端 A 获取了 Master 节点的锁。 Master 节点宕机了，存储锁的 key 暂未同步到 Slave 上。 Slave 节点升级为 Master 节点。 客户端 B 从新的 Master 节点上获取到了同一资源的锁。 在这种情况下，锁的安全性就会被打破，Redis 作者 antirez 针对此问题设计了 Redlock 算法。 Redlock 算法Redlock 算法获取锁时客户端执行步骤： 获取当前时间（start）。 依次向 N 个 Redis 节点请求锁。请求锁的方式与从单节点 Redis 获取锁的方式一致。为了保证在某个 Redis 节点不可用时该算法能够继续运行，获取锁的操作都需要设置超时时间，需要保证该超时时间远小于锁的有效时间。这样才能保证客户端在向某个 Redis 节点获取锁失败之后，可以立刻尝试下一个节点。 计算获取锁的过程总共消耗多长时间（consumeTime = end - start）。如果客户端从大多数 Redis 节点（&gt;= N/2 + 1) 成功获取锁，并且获取锁总时长没有超过锁的有效时间，这种情况下，客户端会认为获取锁成功，否则，获取锁失败。 如果最终获取锁成功，锁的有效时间应该重新设置为锁最初的有效时间减去 consumeTime。 如果最终获取锁失败，客户端应该立刻向所有 Redis 节点发起释放锁的请求。 在释放锁时，需要向所有 Redis 节点发起释放锁的操作，不管节点是否获取锁成功。因为可能存在客户端向 Redis 节点获取锁时成功，但节点通知客户端时通信失败，客户端会认为该节点加锁失败。 Redlock 算法实现了更高的可用性，也不会出现 failover 时失效的问题。但是如果有节点崩溃重启，仍然对锁的安全性有影响。假设共有 5 个 Redis 节点 A、B、C、D、E： 客户端 A 获取了 A、B、C 节点的锁，但 D 与 E 节点的锁获取失败。 节点 C 崩溃重启，但是客户端 A 在 C 上加的锁没有持久化下来，重启后丢失 节点 C 重启后，客户端 B 锁住了 C、D、E，获取锁成功。 在这种情况下，客户端 A 与 B 都获取了访问同一资源的锁。 这里第 2 步中节点 C 锁丢失的问题可能由多种原因引起。默认情况下，Redis 的 AOF 持久化方式是每秒写一次磁盘（fsync），这情况下就有可能丢失 1 秒的数据。我们也可以设置每次操作都触发 fsync，这会影响性能，不过即使这样设置，也有可能由于操作系统的问题导致操作写入失败。 为了解决节点重启导致的锁失效问题，antirez 提出了延迟重启的概念，即当一个节点崩溃之后并不立即重启，而是等待与分布式锁相关的 key 的有效时间都过期之后再重启，这样在该节点重启后也不会对现有的锁造成影响。 一些插曲关于 Redlock 的安全性问题，在分布式系统专家 Martin Kleppmann 和 Redis 的作者 antirez 之间发生过一场争论，这个问题引发了激烈的讨论。关于这场争论的内容可以关注 基于Redis的分布式锁到底安全吗 这篇文章。最后得出的结论是 Redlock 在效率要求的应用中是合理的，所以在 Java 项目中可以使用 Redlock 的 Java 版本 Redission 来控制多节点访问共享资源。但是仍有极端情况会造成 Redlock 的不安全，我们应该知道它在安全性上有哪些不足以及会造成什么后果。如果需要进一步的追求正确性，可以使用 Zookeeper 分布式锁。 相关链接 基于Redis的分布式锁到底安全吗","tags":[{"name":"Distributed Lock","slug":"Distributed-Lock","permalink":"http://changleamazing.com/tags/Distributed-Lock/"}]}]