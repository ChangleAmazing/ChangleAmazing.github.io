<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>大音希声，大象无形</title>
  
  <subtitle>这深夜里一片寂静，是因为你还没有听见声音</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://changleamazing.com/"/>
  <updated>2020-04-20T19:41:09.069Z</updated>
  <id>http://changleamazing.com/</id>
  
  <author>
    <name>ChangleAmazing</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>消息消费</title>
    <link href="http://changleamazing.com/2020/04/20/%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/"/>
    <id>http://changleamazing.com/2020/04/20/%E6%B6%88%E6%81%AF%E6%B6%88%E8%B4%B9/</id>
    <published>2020-04-19T16:45:00.000Z</published>
    <updated>2020-04-20T19:41:09.069Z</updated>
    
    <content type="html"><![CDATA[<h3 id="消息拉取"><a href="#消息拉取" class="headerlink" title="消息拉取"></a>消息拉取</h3><p>消息消费一般有两种模式，推模式与拉模式。<br>推模式是服务端主动将消息推送给消费者，而拉模式是消费者主动向服务端发起请求来拉取消息。<strong>Kafka 中的消息消费基于拉模式。</strong></p><p>拉模式主要方法为 <code>poll()</code> 方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ConsumerRecords&lt;K, V&gt; <span class="title">poll</span><span class="params">(Duration timeout)</span></span>;</span><br></pre></td></tr></table></figure><p>当有消息待消费时，该方法会立即返回。否则，会等待参数 <code>timeout</code> 指定的时间。<strong>从 Kafka 2.0.0 开始，<code>timeout</code> 类型从 <code>long</code> 变为 JDK8 中新的时间类型 <code>Duration</code>。</strong></p><p>Kafka 的消息消费是不断轮询的过程，消费者会重复调用 <code>poll()</code> 方法，获取所订阅的主题的一组消息。</p><p>消费者消费到的每条消息类型为 <code>ConsumerRecord</code>，与发送者发送的消息类型 <code>ProducerRecord</code> 对应。</p><h3 id="消费位移"><a href="#消费位移" class="headerlink" title="消费位移"></a>消费位移</h3><p>Kafka 的分区中，每条消息都有唯一的 offset。这个 offset 在消费端也存在，用来表示消费到的消息在所在分区中的位置。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://changleamazing-1253815386.cos.ap-guangzhou.myqcloud.com/blog/2020-04-20-121854.jpg" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><p><strong>消费位移对应图中的 position，表示下一条需要拉取的消息的位置。</strong><br>在消费端拉取消息时，返回的是没有被消费过的消费集，这需要记录已经被消费的消息的位移，Kafka 将该位移持久化保存，否则当消费者重启之后就无法知道消费位移。另一种情况是当消费端有新的消费者加入之后，分区与消费者的关系会被重新分配，如果不保存分区的消费位移，新绑定的消费者就无法知道从哪个消息开始消费。</p><p>消费位移的存储从 Zookeeper 中转移到了 Kafka 内部主题 <code>_consumer_offsets</code> 中。</p><h3 id="位移提交"><a href="#位移提交" class="headerlink" title="位移提交"></a>位移提交</h3><p>将消费位移持久化的动作称为“提交”，消费者在消费完消息之后需要执行消费位移的提交。</p><p>确定位移提交的时机是一个难题。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://changleamazing-1253815386.cos.ap-guangzhou.myqcloud.com/blog/2020-04-20-175306.jpg" alt="位移提交" title="">                </div>                <div class="image-caption">位移提交</div>            </figure><p>在上图情况下，消费者拉取到了区间 [x+2,x+7] 的消息，并且正在处理 x+5 对应的消息。</p><h4 id="消息处理前提交"><a href="#消息处理前提交" class="headerlink" title="消息处理前提交"></a>消息处理前提交</h4><p>假设在 <code>poll()</code> 方法拉取到消息之后立刻进行位移提交，即消费位移置为 x+8。如果对 x+5 对应消息处理出现异常，在故障恢复之后，重新拉取的消息会从 x+8 开始的，这会导致区间 [x+5,x+7] 的消息未被消费，发生消息丢失的情况。</p><h4 id="消息处理后提交"><a href="#消息处理后提交" class="headerlink" title="消息处理后提交"></a>消息处理后提交</h4><p>假设在 <code>poll()</code> 方法拉取到消息并且将消息处理完毕再提交，如果仍然是处理到 x+5 时发生异常，故障恢复后从 x+2 位置重新开始消费，那么区间 [x+2,x+4] 的消息会被二次消费，发生重复消费的情况。</p><h4 id="自动提交"><a href="#自动提交" class="headerlink" title="自动提交"></a>自动提交</h4><p>Kafka 默认的位移提交方式是自动提交，对应的参数为 <code>enable.auto.commit</code>，值为 true。自动提交的周期由参数 <code>auto.commit.interval.ms</code> 控制，默认值为 5s。</p><p>在默认的方式下，消费者每隔 5s 会将每个分区中最大的消息位移进行提交。提交的动作是在 <code>poll()</code> 方法的逻辑里完成的，在每次真正向服务端发起拉取请求之前会检查是否可以进行位移提交。</p><p>自动提交不需要我们进行额外的处理，但是自动提交也会带来重复消费与消息丢失的问题。<br>当消费一批消息后而在位移提交前消费者崩溃了，那么故障恢复后，这些消息又会被重新消费一次。<br>消息丢失的发生条件会苛刻一些。假设消费者端在拉取到了消息之后，将消息不断地放入本地缓存中，比如 <code>BlockingQueue</code> 中，而另一个线程对 <code>BlockingQueue</code> 中的数据进行处理。此时拉取线程直接返回处理完毕，在下一次拉取时进行位移提交。如果此时 <code>BlockingQueue</code> 中上一次拉取的数据还未被处理，且此时处理线程发生了异常，会导致之前被拉取的消息丢失了。</p><h3 id="控制消费"><a href="#控制消费" class="headerlink" title="控制消费"></a>控制消费</h3><p>在某些应用场景下需要暂停某些分区消费先消费其它分区，之后再恢复该分区的消费。<br>KafkaConsumer 中使用 <code>pause()</code> 与 <code>resume()</code> 方法实现暂停分区消费与恢复分区消费的操作，除此之外，还提供了 <code>paused()</code> 方法返回被暂停消费的分区集合。</p><p>KafkaConsumer 提供了 <code>wakeup()</code> 方法让其他线程安全调用，退出拉取消息的逻辑，抛出 <code>WakeupException</code>。</p><p>当消费端发生异常跳出循环之后，我们必须显示地执行关闭动作来释放占用的资源。KafkaConsumer 提供了 <code>close()</code> 方法来实现资源释放。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">(Duration timeout)</span></span>;</span><br></pre></td></tr></table></figure><p>第一种方法调用之后，会等待 Kafka 进行一些需要的清理操作，如果开启了自动提交消费位移，这里还会触发一次提交，虽然方法参数没有设置时间，但是 Kafka 内部默认等待时间为 30s。<br>第二种方式则限制了在指定时间内完成对 Kafka 关闭的收尾工作，如果时间很短，消费者会在没有自动提交消费位移的情况下被强制关闭。<br><strong>wakeup() 方法不应该被用来中断 close() 方法。</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h3 id=&quot;消息拉取&quot;&gt;&lt;a href=&quot;#消息拉取&quot; class=&quot;headerlink&quot; title=&quot;消息拉取&quot;&gt;&lt;/a&gt;消息拉取&lt;/h3&gt;&lt;p&gt;消息消费一般有两种模式，推模式与拉模式。&lt;br&gt;推模式是服务端主动将消息推送给消费者，而拉模式是消费者主动向服务端发起请求来
      
    
    </summary>
    
    
      <category term="Kafka" scheme="http://changleamazing.com/categories/Kafka/"/>
    
    
      <category term="Kafka" scheme="http://changleamazing.com/tags/Kafka/"/>
    
      <category term="Message Queue" scheme="http://changleamazing.com/tags/Message-Queue/"/>
    
  </entry>
  
  <entry>
    <title>序列化与反序列化</title>
    <link href="http://changleamazing.com/2020/04/19/%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/"/>
    <id>http://changleamazing.com/2020/04/19/%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E5%8F%8D%E5%BA%8F%E5%88%97%E5%8C%96/</id>
    <published>2020-04-18T16:45:00.000Z</published>
    <updated>2020-04-20T19:41:13.285Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka 内部都是以字节数组的形式来传播消息的。<br>生产者使用序列化器将对象转换成字节数组，消费者使用反序列化器将字节数组转换成相应的对象。</p><h3 id="序列化接口"><a href="#序列化接口" class="headerlink" title="序列化接口"></a>序列化接口</h3><p>最常使用的是 <code>StringSerializer</code>，Kafka 也提供了对于 <code>ByteArray</code>、<code>ByteBuffer</code>、<code>Bytes</code>、<code>Double</code>、<code>Integer</code>、<code>Long</code> 这几种类型的序列化器，它们都实现了</p><p><code>org.apache.kafka.common.serialization.Serializer</code> 接口。</p><p>该接口有四个方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Serializer</span>&lt;<span class="title">T</span>&gt; <span class="keyword">extends</span> <span class="title">Closeable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Configure this class.</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> configs configs in key/value pairs</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> isKey whether is for key or value</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs, <span class="keyword">boolean</span> isKey)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Convert &#123;<span class="doctag">@code</span> data&#125; into a byte array.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> topic topic associated with data</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> data typed data</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> serialized bytes</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">byte</span>[] serialize(String topic, T data);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Convert &#123;<span class="doctag">@code</span> data&#125; into a byte array.</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> topic topic associated with data</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> headers headers associated with the record</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> data typed data</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> serialized bytes</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">default</span> <span class="keyword">byte</span>[] serialize(String topic, Headers headers, T data) &#123;</span><br><span class="line">        <span class="keyword">return</span> serialize(topic, data);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * Close this serializer.</span></span><br><span class="line"><span class="comment">     * &lt;p&gt;</span></span><br><span class="line"><span class="comment">     * This method must be idempotent as it may be called multiple times.</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">default</span> <span class="keyword">void</span> <span class="title">close</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p><code>configure()</code> 方法用来配置当前类，<code>serialize()</code> 方法用来执行序列化操作，<code>close()</code> 方法用来关闭当前的序列化器，一般情况下实现类中都不会重写<code>close()</code> 方法，如果重写该方法，必须确保该方法的幂等性，因为这个方法很可能会被 <code>KafkaProducer</code> 调用多次。</p><h3 id="自定义序列化器"><a href="#自定义序列化器" class="headerlink" title="自定义序列化器"></a>自定义序列化器</h3><p>自定义序列化器非常简单，当 Kafka 提供的序列化器的序列化方法不满足我们的需求时，我们可以通过实现 <code>org.apache.kafka.common.serialization.Serializer</code> 接口，并重写其中的 <code>serialize</code> 方法即可。</p><p>之后只需要定义 KafkaProducer 的序列化配置。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">props.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, CustomSerializer<span class="class">.<span class="keyword">class</span>.<span class="title">getName</span>())</span>;</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>上述都是以生产者序列化器作为例子来说明，反序列化器与序列化器的逻辑及自定义方式一致。如果没有特殊需要，不建议自定义序列化器与反序列化器，这样会增加生产者与消费者的耦合度，升级换代容易出错。如果需要自定义序列化器与反序列化器，那么尽量在序列化方法中使用通用的序列化工具来包装，例如 <code>Thrift</code>、<code>ProtoBuf</code> 等。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Kafka 内部都是以字节数组的形式来传播消息的。&lt;br&gt;生产者使用序列化器将对象转换成字节数组，消费者使用反序列化器将字节数组转换成相应的对象。&lt;/p&gt;
&lt;h3 id=&quot;序列化接口&quot;&gt;&lt;a href=&quot;#序列化接口&quot; class=&quot;headerlink&quot; title=&quot;序
      
    
    </summary>
    
    
      <category term="Kafka" scheme="http://changleamazing.com/categories/Kafka/"/>
    
    
      <category term="Kafka" scheme="http://changleamazing.com/tags/Kafka/"/>
    
      <category term="Message Queue" scheme="http://changleamazing.com/tags/Message-Queue/"/>
    
  </entry>
  
  <entry>
    <title>消费组与消费者</title>
    <link href="http://changleamazing.com/2020/04/18/%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E7%BB%84/"/>
    <id>http://changleamazing.com/2020/04/18/%E6%B6%88%E8%B4%B9%E8%80%85%E4%B8%8E%E6%B6%88%E8%B4%B9%E7%BB%84/</id>
    <published>2020-04-17T16:45:00.000Z</published>
    <updated>2020-04-20T19:41:08.257Z</updated>
    
    <content type="html"><![CDATA[<p>消费者负责订阅 Kafka 中的主题，并且从订阅的主题上拉取消息。每个消费者都有一个对应的消费组，当消息发布到主题后，只会被投递给订阅它的消费组中的一个消费者。</p><p><img src="https://changleamazing-1253815386.cos.ap-guangzhou.myqcloud.com/blog/2020-04-14-162633.jpg" alt="Consumer-Group"></p><p>如上图所示，某个主题中共有 4 个分区。消费组 A 和 B 都订阅了这个主题，消费组 A 中有4个消费者，消费组B中有 2 个消费者。按照 Kafka 默认的规则，最后的分配结果是消费组 A 中的每一个消费者分配到 1 个分区，消费组B中的每一个消费者分配到2个分区，两个消费组之间互不影响。<strong>每个消费者只能消费所分配到的分区中的消息</strong>，<strong>即每一个分区只能被一个消费组中的一个消费者所消费。</strong></p><p>对于需要订阅同一个主题的不同服务来说，需要配置不同的消费组，否则会导致同一个消费组内的不同服务都只能消费到该主题中部分分区的消息，导致数据不完整或者状态错误。</p><p>消费组会根据组内消费者的个数，为每个消费者动态分配消费的主题分区个数。这种模型可以让整体消费能力具备横向伸缩性，可以通过增减消费者的个数来控制整体的消费能力。</p><p>如果出现消费组中消费者个数大于主题分区数的情况，会导致某些消费者分配不到分区而无法消费任何消息。</p><p><code>partition.assignment.strategy</code> 参数用来指定分区分配策略。</p><p>Kafka 支持两种消息投递模式：</p><ul><li><p>点对点模式（P2P）</p><p>点对点基于队列，消息生产者发送消息到队列中，消费者从队列中接收消息。一个队列可以存在多个消费者，但是一条消息只有一个消费者能消费到。</p></li><li><p>发布订阅模式（Pub/Sub）</p><p>发布订阅模式基于中间节点，对于 Kafka 来说即主题，这种模式下发布的消息能被所有订阅了该主题的消费者消费。</p></li></ul><p>当所有的消费者都属于同一个消费组时，每个分区的消息只会被一个消费者处理，这属于点对点模式的应用。</p><p>当同一个主题的消费者不属于同一个消费组时，消息会被广播给所有的消费者，即每条消息会被所有的消费者处理，这属于发布/订阅模式的应用。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;消费者负责订阅 Kafka 中的主题，并且从订阅的主题上拉取消息。每个消费者都有一个对应的消费组，当消息发布到主题后，只会被投递给订阅它的消费组中的一个消费者。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://changleamazing-1253815386.cos.a
      
    
    </summary>
    
    
      <category term="Kafka" scheme="http://changleamazing.com/categories/Kafka/"/>
    
    
      <category term="Kafka" scheme="http://changleamazing.com/tags/Kafka/"/>
    
      <category term="Message Queue" scheme="http://changleamazing.com/tags/Message-Queue/"/>
    
  </entry>
  
  <entry>
    <title>生产者整体架构</title>
    <link href="http://changleamazing.com/2020/04/14/%E7%94%9F%E4%BA%A7%E8%80%85%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%8E%9F%E7%90%86/"/>
    <id>http://changleamazing.com/2020/04/14/%E7%94%9F%E4%BA%A7%E8%80%85%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%8E%9F%E7%90%86/</id>
    <published>2020-04-14T01:11:00.000Z</published>
    <updated>2020-04-20T19:41:06.640Z</updated>
    
    <content type="html"><![CDATA[<p>消息在发往 Kafka 之前，可能需要经历拦截器、序列化器和分区器等一系列的处理，生产者客户端的整体架构如下图所示：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://changleamazing-1253815386.cos.ap-guangzhou.myqcloud.com/blog/2020-04-11-220442.jpg" alt="生产者整体架构" title="">                </div>                <div class="image-caption">生产者整体架构</div>            </figure><p>可以看到，在生产者端主要有两个线程协调运行，分别为主线程与 Sender 线程。</p><p>其中主线程的作用是处理 KafkaProducer 创建消息，通过拦截器、序列化器和分区器的作用之后缓存消息到消息累加器（也称为消息收集器）中；而 Sender 线程则负责从消息收集器中获取消息并将其发送到 Kafka 中，其中 InFlightRequests 用来缓存已经被 Sender 线程发送但是还没有收到相应的请求。 </p><h3 id="RecordAccumulator"><a href="#RecordAccumulator" class="headerlink" title="RecordAccumulator"></a>RecordAccumulator</h3><p>RecordAccumulator 是消息收集器，主要用来缓存要被发送至 Kafka 的消息，便于 Sender 线程批量发送，这样可以减少网络传输的资源消耗。RecordAccumulator 缓存的大小通过生产者客户端参数 <code>buffer.memory</code> 配置，默认大小为 <code>32MB</code>。</p><p>当生产者生产消息速度超过 Sender 线程发送至服务器的速度时，会导致消息积压在消息收集器中。当消息收集器缓存空间被填满时，KafkaProducer 调用 sender() 方法会被阻塞，当阻塞时间超过 <code>max.block.ms</code> 指定的时间就会抛出异常，默认为 60 秒。</p><p>RecordAccumulator 内部为每个分区都维护了一个<strong>双端队列</strong>，队列中存放的内容为 <code>ProducerBatch</code>，ProducerBatch 是一个消息批次，可以包含一个或多个 ProducerRecord。主线程中发送过来的消息都会被追加到双端队列中，其中较小的 <code>ProducerRecord</code> 会被拼凑成一个较大的 <code>ProducerBatch</code>。</p><p>消息都是以字节的形式传输的，在发送之前需要创建一块内存区域保存对应的消息。内存频繁创建与释放非常耗资源，在 RecordAccumulator 内部有一个 BufferPool，用来实现 ByteBuffer 的复用。BufferPool 只管理 <code>batch.size</code> 指定大小以下的 ByteBuffer，默认值为 <code>16KB</code>。</p><p>消息发送至 RecordAccumulator 中包括以下几个步骤：</p><ol><li>当一条消息（ProducerRecord）流入 RecordAccumulator 时，会先寻找与消息分区所对应的双端队列（如果没有则新建）</li><li>从这个双端队列的尾部获取一个 ProducerBatch（如果没有则新建）</li><li>查看 ProducerBatch 中是否还可以写入这个 ProducerRecord，如果可以则写入，如果不可以则需要创建一个新的 ProducerBatch</li><li>在新建 ProducerBatch 时评估这条消息的大小是否超过 batch.size 参数的大小，如果不超过，那么就以 batch.size 参数的大小来创建 ProducerBatch，这样在使用完这段内存区域之后，可以通过 BufferPool 的管理来进行复用；如果超过，那么就以评估的大小来创建 ProducerBatch，这段内存区域不会被复用。</li></ol><h3 id="InFlightRequests"><a href="#InFlightRequests" class="headerlink" title="InFlightRequests"></a>InFlightRequests</h3><p>InFlightRequests 用来缓存已经被 Sender 线程发送但是还没有收到响应的请求。 </p><p>在介绍 InFlightRequests 存放的消息类型之前，要说明消息的保存形式的转换。</p><p>在主线程发送消息时，我们关注的是消息发往哪个分区，所以在 RecordAccumulator 中消息的保存形式为 <code>&lt;Partition,Deque&lt;ProducerBatch&gt;&gt;</code>，但是被 Sender 线程处理时，关注的是发送到 broker 集群中的哪个节点，所以消息保存的形式被转为 <code>&lt;Node,List&lt;ProducerBatch&gt;&gt;</code>，之后会被进一步封装成 <code>&lt;Node,Request&gt;</code>，其中 Request 是指 Kafka 的各种协议请求，对于消息发送来说就是 ProduceRequest。</p><p>当 Sender 线程将未收到响应的请求保存至 InFlightRequests 中，InFlightRequests 保存对象的形式是 <code>Map&lt;NodeId,Deque&gt;</code>。InFlightRequests 可以通过配置参数 <code>max.in.flight.requests.per.connection</code> 限制每个连接最多缓存的请求数，默认值为 5。即当某个连接中缓存了五个未响应的请求之后，就不能再向该连接发送更多的请求了，除非之后缓存的请求中收到了回复。</p><p>InFlightRequests 还可以获得 <code>leastLoadedNode</code>，即负载最小的 Node。负载最小是通过比较 Node 在 InFlightRequests 中未确认的请求决定的，未确认的请求越多，则认为负载越大。所以 Kafka 会选择 <code>leastLoadedNode</code> 发送请求，以便于能够尽快发出。</p><p>对于消息发送来说，在 RecordAccumulator 中就已经确定了分区，确定分区之后，要发送的 broker 即为该分区的 leader 副本所在的 broker，所以也就确定了 Node，无法根据 <code>leastLoadedNode</code> 来切换节点。这里 <code>leastLoadedNode</code> 是用来处理元数据请求、消费者组播协议的交互。</p><p>元数据是指 Kafka 集群的元数据，这些元数据具体记录了集群中有哪些主题，这些主题有哪些分区，每个分区的 leader 副本分配在哪个节点上，follower 副本分配在哪些节点上，哪些副本在 AR、ISR 等集合中，集群中有哪些节点，控制器节点又是哪一个等信息。</p><p>客户端可以自己发现 broker 节点的地址，这一过程也属于元数据相关的更新操作。与此同时，分区数量及 leader 副本的分布都会动态地变化，客户端也需要动态地捕捉这些变化。</p><p>而元数据的更新是在客户端内部进行的，对客户端的外部使用者不可见。当需要更新元数据时，会先挑选出 <code>leastLoadedNode</code>，然后向这个 Node 发送 <code>MetadataRequest</code> 请求来获取具体的元数据信息。这个更新操作是由 Sender 线程发起的，在创建完 MetadataRequest 之后同样会存入 InFlightRequests，之后各个 broker 会同步元数据。</p><h2 id="生产者参数"><a href="#生产者参数" class="headerlink" title="生产者参数"></a>生产者参数</h2><h3 id="acks"><a href="#acks" class="headerlink" title="acks"></a>acks</h3><p>指定分区必须有几个副本收到消息生产者才会认为这条消息成功写入。该值设置到消息可靠性和吞吐量之间的权衡。</p><p>acks 有三种类型的<strong>字符串值</strong>：</p><ul><li>acks = 1。这是默认值。即只要分区的 leader 副本成功写入就会收到来自己服务器的成功响应。如果消息已写入 leader 副本，但是在被其它 follower 拉取之前 leader 节点崩溃了，这条消息就丢失掉了。<strong>这是可靠性与吞吐量之间的折中方案。</strong></li><li>acks = 0。生产者发送消息之后不需要等待服务端的响应。消息从发送到写入 Kafka 的过程中出现异常就会丢失。当其它配置相同时，acks 设置为 0 可以达到最大的吞吐量。</li><li>acks = -1 或 acks = all。需要等待 ISR 中的所有副本都成功写入消息之后才能收到服务器的成功响应。其它配置相同时，acks 设置为 -1 可以保证最强的可靠性。但是有可能出现 ISR 集合中只有 leader 副本的情况，这与 acks = 1 情况一致。</li></ul><blockquote><p>Kafka 可以保证分区消息有序，如果生产者按照一定的顺序发送消息，那么这些消息也会顺序的写入分区。</p><p>但是如果 acks 参数为非零值，即必须要有副本确认收到消息，并且 <code>max.in.flight.requests.per.connection</code> 参数（即 InFlightRequests 中缓存的请求数量）配置大于 1，就可能会出现消息错序的情况。</p><p>假设第一批次消息写入失败，而第二批次消息发送成功，生产者就会重新发送第一批次的消息，导致第二批次消息比第一批次消息更早写入分区中，消息发生错序。</p><p>如果需要保证消息顺序时，建议把 <code>max.in.flight.requests.per.connection</code> 配置为 1，而不是配置 acks = 0，这样第一批次消息被缓存在 InFlightRequests 中时，第二批次消息无法发送，直到第一批次消息重试成功或者超过重试次数时才会发送第二批次消息。</p></blockquote><h3 id="max-request-size"><a href="#max-request-size" class="headerlink" title="max.request.size"></a>max.request.size</h3><p>限制生产者客户端能发送的消息的最大值，默认为 <code>1048576B</code>，即 <code>1MB</code>。</p><p>该值与其它配置值有联动关系，一般情况下不改动。比如 broker 的 <code>message.max.bytes</code> 参数，如果  <code>message.max.bytes</code>  配置为 <code>10B</code>，而 <code>max.request.size</code> 配置为 <code>20B</code>。此时发送一条 15B 的消息时，生产者客户端也会收到异常。</p><h3 id="retries"><a href="#retries" class="headerlink" title="retries"></a>retries</h3><p>指定发生异常时生产者重试的次数，默认为 0，即不进行任何重试。</p><h3 id="retry-backoff-ms"><a href="#retry-backoff-ms" class="headerlink" title="retry.backoff.ms"></a>retry.backoff.ms</h3><p>指定两次重试之间的时间间隔，避免无效的频繁重试。</p><h3 id="compression-type"><a href="#compression-type" class="headerlink" title="compression.type"></a>compression.type</h3><p>指定消息的压缩方式，默认值为 none，即不压缩消息。该参数可以配置为 gzip/snappy/lz4。对消息进行压缩可以减少网络传输量，提高整体性能，但是压缩会耗费一定的时间，如果对时间有要求，则不推荐对消息进行压缩。</p><h3 id="connections-max-idle-ms"><a href="#connections-max-idle-ms" class="headerlink" title="connections.max.idle.ms"></a>connections.max.idle.ms</h3><p>指定连接的最大闲置时间，默认为 <code>540000ms</code>，即 9 分钟。</p><h3 id="linger-ms"><a href="#linger-ms" class="headerlink" title="linger.ms"></a>linger.ms</h3><p>指定生产者发送 ProducerBatch 之前等待更多 ProducerRecord 加入 ProducerBatch 的时间，默认值为 0。即客户端会在ProducerBatch 被填满或者等待时间超过 linger.ms 配置值之后发送出去。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;消息在发往 Kafka 之前，可能需要经历拦截器、序列化器和分区器等一系列的处理，生产者客户端的整体架构如下图所示：&lt;/p&gt;
&lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div class=&quot;img-lightbox&quot;&gt;
 
      
    
    </summary>
    
    
      <category term="Kafka" scheme="http://changleamazing.com/categories/Kafka/"/>
    
    
      <category term="Kafka" scheme="http://changleamazing.com/tags/Kafka/"/>
    
      <category term="Message Queue" scheme="http://changleamazing.com/tags/Message-Queue/"/>
    
  </entry>
  
  <entry>
    <title>Kafka 基础</title>
    <link href="http://changleamazing.com/2020/04/13/Kafka%20%E5%9F%BA%E7%A1%80/"/>
    <id>http://changleamazing.com/2020/04/13/Kafka%20%E5%9F%BA%E7%A1%80/</id>
    <published>2020-04-12T16:45:00.000Z</published>
    <updated>2020-04-20T19:39:58.989Z</updated>
    
    <content type="html"><![CDATA[<p>Kafka 是 LinkedIn 开发的一个多分区、多副本且基于 ZooKeeper 协调的分布式消息系统。</p><p>Kafka 主要用三个用途：</p><ul><li>消息系统<br>Kafka 与消息中间件一样具备系统解耦、流量削峰、异步通信等功能。除此之外，Kafka 还提供了<strong>消息顺序性保障</strong>以及<strong>回溯消费</strong>的功能</li><li>存储系统<br>消息持久化到磁盘中，相比于内存存储的系统降低了数据丢失的风险</li><li>流式处理平台<br>Kafka 为流式处理框架提供了可靠的数据来源，还提供了一个完整的流式处理类库</li></ul><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://changleamazing-1253815386.cos.ap-guangzhou.myqcloud.com/20200331184722.png" alt="Kafka 结构" title="">                </div>                <div class="image-caption">Kafka 结构</div>            </figure><p>如上图，Kafka 体系结构主要包括三个部分：</p><ul><li>Producer<br>生产者，消息发送方</li><li>Consumer<br>消费者，消息接收方</li><li>Broker<br>服务代理节点。</li></ul><p>Kafka 中还有两个特别重要的概念：主题（Topic）与 分区（Partition）。<br>Kafka 中的消息以 Topic 为单元进行归类，Producer 将消息发送到指定的 Topic，Consumer 则订阅 Topic 消费在该单元上的消息。</p><p>主题是逻辑概念，一个主题可以细分为多个分区，每个分区包含的消息是不同的，分区在存储层面相当于<strong>可追加的日志文件</strong>，消息被追加到分区日志文件的时候都会被分配一个特定的偏移量（offset）。<br>offset 是消息在分区中的唯一标识，Kafka 用它来保证消息在<strong>分区</strong>中的顺序性(Kafka 保证分区有序而非主题有序）。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://changleamazing-1253815386.cos.ap-guangzhou.myqcloud.com/20200404150034.png" alt="主题中的分区" title="">                </div>                <div class="image-caption">主题中的分区</div>            </figure><p>如上图所示，假设主题中有四个分区，消息被顺序追加到分区日志文件尾部，offset 从 0 开始。一个主题中的分区可以分布在不同的 broker 上。</p><p>Kafka 为分区引入了多副本（Replica）机制，通过增加副本数量可以提升容灾能力。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://changleamazing-1253815386.cos.ap-guangzhou.myqcloud.com/20200404154135.png" alt="多副本机制" title="">                </div>                <div class="image-caption">多副本机制</div>            </figure><p>副本之间的关系是一主多从，其中 leader 副本负责处理读写请求，follower 副本只负责与 leader 副本同步消息，follower 副本中的消息与 leader 副本数据同步存在一定延迟。Kafka 通过算法来实现副本在 broker 上均匀分布，所以当 Kafka 集群中某个 broker 失效时，如果该 broker 中存在某分区的 leader 副本时，多副本机制能从该分区分布在其它 broker 上的 follower 副本中选举出新的 leader 副本，实现了故障的自动转移。</p><p>Kafka 消费端也具备一定的容灾能力。Consumer 使用拉模式从服务获取消息，并且会保存消费的具体位置。消费者在宕机后恢复上线时，可以根据之前保存的位置重新拉取需要的消息进行消费，这样就不会造成消息丢失。</p><p>分区中所有副本集合称为 AR（Assigned Replicas），所有与 leader 副本保持一定程度同步的副本（包括 leader 副本）集合称为 ISR（In-Sync Replicas），这里的一定程度是指可忍受的同步滞后范围，通过参数可以配置。同步滞后过多的部分组成 OSR（Out-of-Sync Replicas）。<br><strong>ASR = ISR + OSR。</strong><br>正常情况下，所有 follower 副本都应该与 leader 副本保持一定程序的同步，此时 AR = ISR，OSR 集合为空。<br>ISR 与 OSR 集合中的副本状态可能会发生变化，当 ISR 集合中副本滞后太多时，会被转移到 OSR 集合中。当 OSR 集合中副本在可忍受的滞后时间内又同步到了 leader 副本最新状态，它就会被转移到 ISR 集合中。<br><strong>默认情况下，若 leader 副本发生故障时，ISR 集合中副本才有资格被选举为新的 leader。</strong></p><p>ISR 与 HW（High Watermark） 和 LEO（Log End Offset） 也有关系。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://changleamazing-1253815386.cos.ap-guangzhou.myqcloud.com/20200404162057.png" alt="HW 和 LEO" title="">                </div>                <div class="image-caption">HW 和 LEO</div>            </figure><p>LEO 标识当前日志文件中下一条待写入消息的 offset。ISR 集合中每个副本都会维护自身的 LEO，而这些副本中最小的 LEO 即为分区的 HW，消费者只能消费 HW 之前的消息。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Kafka 是 LinkedIn 开发的一个多分区、多副本且基于 ZooKeeper 协调的分布式消息系统。&lt;/p&gt;
&lt;p&gt;Kafka 主要用三个用途：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;消息系统&lt;br&gt;Kafka 与消息中间件一样具备系统解耦、流量削峰、异步通信等功能。除此之外，
      
    
    </summary>
    
    
      <category term="Kafka" scheme="http://changleamazing.com/categories/Kafka/"/>
    
    
      <category term="Kafka" scheme="http://changleamazing.com/tags/Kafka/"/>
    
      <category term="Message Queue" scheme="http://changleamazing.com/tags/Message-Queue/"/>
    
  </entry>
  
  <entry>
    <title>百度分布式 ID 生成器</title>
    <link href="http://changleamazing.com/2020/02/03/%E5%88%86%E5%B8%83%E5%BC%8F%20id%20%E7%94%9F%E6%88%90%E5%99%A8/"/>
    <id>http://changleamazing.com/2020/02/03/%E5%88%86%E5%B8%83%E5%BC%8F%20id%20%E7%94%9F%E6%88%90%E5%99%A8/</id>
    <published>2020-02-03T02:18:47.000Z</published>
    <updated>2020-04-20T19:40:32.587Z</updated>
    
    <content type="html"><![CDATA[<p>分布式 ID 生成器是分布式项目开发中的常用工具，弄懂其原理对理解分布式有一定的帮助。</p><a id="more"></a><p>绝大多数公司使用的分布式 ID 生成器都是依赖于雪花算法（<code>snowflake）</code>实现的。</p><h2 id="snowflake"><a href="#snowflake" class="headerlink" title="snowflake"></a>snowflake</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://changleamazing-1253815386.cos.ap-guangzhou.myqcloud.com/blog/2020-02-03-045141.jpg" alt="snowflake" title="">                </div>                <div class="image-caption">snowflake</div>            </figure><p>如上图所示，雪花算法生成 id 为 64 位二进制串，由几个部分组成：</p><ol><li>1 位标识位，默认为 0，因为二进制首位为符号位，一般生成的 id 都要求是正数，所以固定为 0</li><li>41 位时间戳，可以表示的时间为 69 年</li><li>10 位工作机器 id，记录工作机器 id。可以部署在 $2^{10}$ (1024) 个节点上，包括 5 位 datacenterId 和 5 位 workerId</li><li>12 位自增序列。记录同一时间戳内产生的不同 id，支持的序号为$2^{12}$（4096）个</li></ol><p>这样的设计可以保证所有生成的 id 按照时间趋势递增，并且不会产生重复的 id，也可以根据实际节点数扩展或缩减工作机器 id 部分的位数。</p><p>雪花算法的主要缺点是时钟回拨问题。</p><blockquote><p>时钟回拨是指服务器时间因为某些原因导致时间回退。可能导致时钟回拨的原因有多种，比如服务器使用了本地时间，然后服务器校时服务修正了系统时间。</p></blockquote><p>这样会导致生成一个已经使用过的 ID。</p><h2 id="百度-UidGenerator"><a href="#百度-UidGenerator" class="headerlink" title="百度 UidGenerator"></a>百度 UidGenerator</h2><p>百度的 <code>UidGenerator</code> 也是基于 <code>snowflake</code> 来实现的，不过调整了生成的 id 中的组成部分顺序。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://changleamazing-1253815386.cos.ap-guangzhou.myqcloud.com/blog/2020-02-03-112957.jpg" alt="UIDGenerator" title="">                </div>                <div class="image-caption">UIDGenerator</div>            </figure><p>如上图所示，<code>UidGenerator</code> 生成的 64 位二进制串主要包括以下几个部分：</p><ol><li>sign：1 位，与 snowflake 一致，固定为 1，即生成的 UID 为正数</li><li>delta seconds：28 位，时间戳，相对于时间基点 <code>2016-05-20</code> 的增量值，单位：秒，最多可支持约 8.7 年</li><li>worker id：22位，机器 id，每次机器启动（包括重启）时由数据库（<code>MySQL</code> 内置 <code>WorkerID</code> 分配器）分配（也可以自定义实现）。</li><li>sequence：13位，同一个时间戳的并发序列，可以支持$2^{13}$ (8192) 个并发。</li></ol><p> <code>UidGenerator</code> 有两种实现方式：<code>DefaultUidGenerator</code>  和 <code>CachedUidGenerator</code>。</p><h3 id="DefaultUIDGenerator"><a href="#DefaultUIDGenerator" class="headerlink" title="DefaultUIDGenerator"></a>DefaultUIDGenerator</h3><h4 id="delta-seconds"><a href="#delta-seconds" class="headerlink" title="delta seconds"></a>delta seconds</h4><p>这个值是当前时间与 <code>epoch</code>时间的时间差，单位为秒。<code>epoch</code> 时间默认为 <code>2016-09-20</code>，需要将它配置为生成分布式 ID 服务上线的时间。</p><h4 id="worker-id"><a href="#worker-id" class="headerlink" title="worker id"></a>worker id</h4><p>worker id 是在机器启动时通过 MySQL 的内置 WorkerID 分配器分配的。UidGenerator 会在生成分布式 ID 的实例启动的时候，向数据库的表中插入一行数据，数据的 ID 值就是 workerId 的值。由于 workerId 默认为 22 位，所以所有实例重启次数不超过 $2^{22} - 1$ 次。</p><h4 id="sequence"><a href="#sequence" class="headerlink" title="sequence"></a>sequence</h4><p>生成 sequence 部分的代码通过 <code>synchronized</code> 关键字保证线程安全，通过简单的异常处理来避免时钟回拨问题。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">synchronized</span> <span class="keyword">long</span> <span class="title">nextId</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> currentSecond = getCurrentSecond();</span><br><span class="line">    <span class="keyword">if</span> (currentSecond &lt; lastSecond) &#123;</span><br><span class="line">        <span class="keyword">long</span> refusedSeconds = lastSecond - currentSecond;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> UidGenerateException(<span class="string">"Clock moved backwards. Refusing for %d seconds"</span>, refusedSeconds);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (currentSecond == lastSecond) &#123;</span><br><span class="line">        sequence = (sequence + <span class="number">1</span>) &amp; bitsAllocator.getMaxSequence();</span><br><span class="line">        <span class="keyword">if</span> (sequence == <span class="number">0</span>) &#123;</span><br><span class="line">            currentSecond = getNextSecond(lastSecond);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        sequence = <span class="number">0L</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    lastSecond = currentSecond;</span><br><span class="line">    <span class="keyword">return</span> bitsAllocator.allocate(currentSecond - epochSeconds, workerId, sequence);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果当前时间与上一次生成 id 时间为同一个时间戳，则增加 <code>sequence</code>。如果 <code>sequence</code> 自增值超过 $，就会通过自旋等待下一秒，而不是直接抛出异常。</p><p>如果当前时间是新的一秒，那么将 <code>sequence</code> 置为 0，重新开始分配该秒对应的 id。</p><h3 id="CachedUIDGenerator"><a href="#CachedUIDGenerator" class="headerlink" title="CachedUIDGenerator"></a>CachedUIDGenerator</h3><p><code>CachedUidGenerator</code> 是 <code>UidGenerator</code> 的重要改进实现。它利用了 <code>RingBuffer</code>（与 <a href="https://github.com/LMAX-Exchange/disruptor/tree/master" target="_blank" rel="noopener">disruptor</a> 一致)。</p><h4 id="RingBuffer"><a href="#RingBuffer" class="headerlink" title="RingBuffer"></a>RingBuffer</h4><p><code>RingBuffer</code> 本质上是一个数组，数组中的每个项被称为 <code>slot</code>。<br><code>CachedUidGenerator</code> 设计了两个 <code>RingBuffer</code>，一个用来保存唯一 ID，一个保存 flag。</p><img src="https://changleamazing-1253815386.cos.ap-guangzhou.myqcloud.com/blog/2020-02-06-023533.jpg" alt="Uid-Genrator RingBuffer" style="zoom:67%;" /><p>每个 <code>RingBuffer</code> 容量为 <code>SnowFlake</code> 算法中 <code>sequence</code> 部分最大值，且为 $2^{n}$，对于 <code>UidGenerator</code> 默认设计来说，即为 $2^{13}$。</p><p><code>UID-RingBuffer</code> 中 <code>Tail</code> 与 <code>Cursor</code> 指针用来读写 <code>slot</code>。其中，<code>Tail</code> 指针表示 <code>Producer</code> 生成的最大序号（此序号从 0 开始，持续递增）。<code>Cursor</code> 指针表示 <code>Consumer</code> 消费到的最小序号。</p><p>这两个指针不能超过对方。若 <code>Cursor</code> 指针超过 <code>Tail</code>，则说明消费了还未生产序号，所以当 <code>Cursor</code> 赶上 <code>Tail</code> 时，应该通过 <code>RejectedTakeBufferHandler</code> 指定 <code>TakeRejectPolicy</code>。</p><p>若 <code>Tail</code> 指针超过 <code>Cursor</code> 指针，则说明生产者覆盖了还未消费的 <code>slot</code>。所以当 <code>Tail</code> 赶上 <code>Cursor</code> 时，应该通过 <code>RejectedPutBufferHandler</code> 指定 <code>PutRejectPolicy</code>。</p><p><code>Flag-Ringbuffer</code> 用来记录每个 <code>slot</code> 的状态（是否可填充、是否可消费）。</p><p>由于数组元素在内存中是连续分配的，这样可以最大程度利用 <code>Cpu Cache</code> 提升性能，但是会带来 <code>伪共享</code> 问题。</p><p>为了解决该问题，<code>Uid-Generator</code> 在 <code>Tail</code>、<code>Cursor</code>、<code>Flag-RingBuffer</code> 中采用 <code>CacheLine</code> 补齐方式。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://changleamazing-1253815386.cos.ap-guangzhou.myqcloud.com/blog/2020-02-06-033131.png" alt="FalseSharing" title="">                </div>                <div class="image-caption">FalseSharing</div>            </figure><p>这里的说明可以看 <a href="https://github.com/baidu/uid-generator/issues/4" target="_blank" rel="noopener"> RingBuffer 中补齐问题</a> 。</p><h4 id="RingBuffer-填充时机"><a href="#RingBuffer-填充时机" class="headerlink" title="RingBuffer 填充时机"></a>RingBuffer 填充时机</h4><p><code>RingBuffer</code> 共有三种填充方式</p><ul><li><p>初始化预填充</p><p><code>RingBuffer</code> 初始化时，预先填充整个 <code>RingBuffer</code>。</p></li><li><p>即时填充</p><p>消费 <code>slot</code> 时，即时检查剩余可以消费的 <code>slot</code>（<code>tail - cursor</code>)。如果小于设定阈值，则填充空余 <code>slots</code>。</p></li><li><p>周期填充</p><p>通过 <code>Schedule</code> 线程，定时补全空闲 <code>slots</code>。</p></li></ul><p>上面分析了 <code>CachedUidGenerator</code> 依赖的数据结构，下面分析它的实现。实际上它继承了 <code>DefaultUidGenerator</code>，所以它是对 <code>DefaultUidGenerator</code> 的增强。</p><h4 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h4><p><code>CachedUidGenerator</code> 在初始化时会给 <code>workerId</code> 赋值，方式与 <code>DefaultUidGenerator</code> 一致。还会初始化 <code>RingBuffer</code>，这个过程包括的操作有：</p><ol><li>根据 <code>boostPower</code> 确定 <code>RingBuffer</code> 的 <code>size</code></li><li>构造 <code>RingBuffer</code>，默认 <code>paddingFactor</code> 为 50。即当 <code>RingBuffer</code> 中剩余可用 ID 数量少于 50% 时，就触发一个异步线程往 <code>RingBuffer</code> 中填充新的 ID，直到填满为止</li><li>判断是否配置了 <code>scheduleInterval</code> 属性值，这个值表示检查填充的周期。默认不配置</li><li>初始化 <code>Put</code> 操作拒绝策略，对应属性 <code>rejectedPutBufferHandler</code>。即当 <code>RingBuffer</code> 已满，无法继续填充时的操作策略。默认情况下会丢弃<code>Put</code> 操作，记录日志。如果有需求，可以自定义实现 <code>RejectedPutBufferHandler</code> 接口</li><li>初始化 <code>Take</code> 操作拒绝策略，对应属性 <code>rejectedTakeBufferHandler</code>。即 <code>RingBuffer</code> 中没有可以使用的 ID 时的操作策略。默认情况下会记录日志并抛出 <code>UidGenerateException</code> 异常。如果有需求，可以自定义实现 <code>RejectedTakeBufferHandler</code> 接口</li><li>初始化填满 <code>RingBuffer</code> 中所有 <code>slot</code></li><li>开启 <code>buffer</code> 补丁线程（需配置 <code>scheduleInterval</code> ）</li></ol><p>第二步中的异步线程实现是 <code>UidGenerator</code> 解决时钟回拨的关键。在满足填充新的 ID 条件时，通过时间值递增得到新的时间值，而不是获取当前时间。</p><h4 id="取值"><a href="#取值" class="headerlink" title="取值"></a>取值</h4><p><code>RingBuffer</code> 初始化之后，就是取值过程了：</p><ol><li>如果剩余可用 ID 百分比低于 <code>paddingFactor</code> 参数指定值，就会异步生成若干个 ID 集合，直到将 <code>RingBuffer</code> 填满。</li><li>如果获取值的位置追上了 <code>tail</code> 指针，就会执行 <code>Task</code> 操作的拒绝策略。</li><li>获取 <code>slot</code> 中的分布式 ID。</li><li>将该 <code>slot</code> 对应的 <code>flag</code> 设置为 <code>CAN_PUT_FLAG</code>。</li></ol><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>绝大多数分布式 ID 生成器都是基于 <code>SnowFlake</code> 来实现的，而 <code>SnowFlake</code> 也有一些缺点。</p><p>本文中提到 <code>Uid-Generator</code> 通过自增列、<code>RingBuffer</code> 以及时间递增的措施解决了 <code>SnowFlake</code> 的传统问题。</p><p>这其中也涉及到一些计算机底层原理，关于该部分知识的解析会在其它文章中继续分析。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;分布式 ID 生成器是分布式项目开发中的常用工具，弄懂其原理对理解分布式有一定的帮助。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Distributed system" scheme="http://changleamazing.com/categories/Distributed-system/"/>
    
    
      <category term="Distributed system" scheme="http://changleamazing.com/tags/Distributed-system/"/>
    
  </entry>
  
  <entry>
    <title>Redis 数据持久化</title>
    <link href="http://changleamazing.com/2020/01/02/Redis%20%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/"/>
    <id>http://changleamazing.com/2020/01/02/Redis%20%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96/</id>
    <published>2020-01-01T18:02:32.000Z</published>
    <updated>2020-04-20T19:39:49.477Z</updated>
    
    <content type="html"><![CDATA[<p><code>Redis</code> 是一种内存型数据库，一旦服务器进程退出，数据库的数据就会丢失。为了解决这个问题，<code>Redis</code> 提供了 <code>RDB</code> 持久化、<code>AOF</code> 持久化、<code>RDB-AOF</code> 混合持久化等多种持久化方式，将内存中的数据保存到磁盘中，避免数据的丢失。</p><a id="more"></a><h2 id="RDB-持久化"><a href="#RDB-持久化" class="headerlink" title="RDB 持久化"></a>RDB 持久化</h2><p><strong><code>RDB</code> 持久化是 <code>Redis</code> 默认的持久化方式</strong>。</p><p><code>RDB</code> 持久化会创建一个经过压缩的以 <code>.rdb</code> 结尾的二进制文件，其中<strong>包含了服务器在各个数据库中存储的键值对数据等信息</strong>。</p><h3 id="RDB-文件创建"><a href="#RDB-文件创建" class="headerlink" title="RDB 文件创建"></a>RDB 文件创建</h3><p>创建 <code>RDB</code>文件有多种方式。用户可以使用 <code>SAVE</code> 或者 <code>BGSAVE</code> 命令手动创建 <code>RDB</code> 文件，也可以通过配置 <code>save</code> 配置项使服务器在满足指定条件时自动执行 <code>BGSAVE</code> 命令。</p><h4 id="SAVE"><a href="#SAVE" class="headerlink" title="SAVE"></a>SAVE</h4><p>用户可以通过 <code>SAVE</code> 命令让 <code>Redis</code> 服务器以<strong>同步方式</strong>创建 <code>RDB</code> 文件。</p><p><code>SAVE</code> 是无参数命令，如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; SAVE</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>在 <code>SAVE</code> 命令执行期间， <code>Redis</code> 服务器将阻塞，直到 <code>RDB</code> 文件创建完毕。</p><p>当执行 <code>SAVE</code> 命令时，如果本地已经存在相应的 <code>RDB</code> 文件，则会在新的 <code>RDB</code> 文件创建完成之后删除原有的 <code>RDB</code> 文件。</p><p><code>SAVE</code> 命令的复杂度为 <code>O(N)</code>， <code>N</code> 表示 <code>Redis</code> 服务器所有数据库包含的键值对的总数。</p><h4 id="BGSAVE"><a href="#BGSAVE" class="headerlink" title="BGSAVE"></a>BGSAVE</h4><p>因为 <code>SAVE</code> 命令是同步操作，会阻塞服务器，导致执行此命令期间 <code>Redis</code> 无法执行其它命令。所以 <code>Redis</code> 提供了 <code>SAVE</code> 命令的异步版本 — <code>BGSAVE</code>。<code>BGSAVE</code> 会使用子进程创建 <code>RDB</code> 文件。</p><p><code>BGSAVE</code> 也是无参数命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; BGSAVE</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>虽然 <code>BGSAVE</code> 的异步操作不会使服务器在创建  <code>RDB</code> 文件过程中阻塞，但是创建子进程的过程会造成短时间的阻塞。</p><p>父进程调用操作系统 <code>fork</code> 函数创建一个子进程，而 <code>fork</code> 函数在父进程占用内存越大时，创建子进程耗时越长。</p><p><code>BGSAVE</code> 命令的复杂度为 <code>O(N)</code>， <code>N</code> 表示 <code>Redis</code> 服务器所有数据库包含的键值对的总数。</p><h4 id="配置自动创建-RDB-文件"><a href="#配置自动创建-RDB-文件" class="headerlink" title="配置自动创建 RDB 文件"></a>配置自动创建 RDB 文件</h4><p>除了通过 <code>SAVE</code> 与 <code>BGSAVE</code> 命令手动创建 <code>RDB</code> 文件外，还可以通过在配置文件中配置 <code>save</code> 选项，让服务器在满足指定条件时自动执行 <code>BGSAVE</code> 命令。</p><p><code>save</code> 配置项选项如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">save  &lt;seconds&gt;  &lt;changes&gt;</span><br></pre></td></tr></table></figure><p><code>seconds</code>  参数指定触发持久化操作的周期，<code>changes</code>  参数用来指定触发持久化操作所需要的修改次数。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">save  60  10000</span><br></pre></td></tr></table></figure><p>这个配置表示服务器在 60s 内至少执行了 10000 次修改时，服务器会自动执行 <code>BGSAVE</code> 命令。</p><p><code>Redis</code> 默认持久化方式为 <code>RDB</code>，如果不改变默认配置，那么 <code>Redis</code> 使用的 <code>save</code> 选项为：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save  60  10000</span><br><span class="line">save  300  100</span><br><span class="line">save  3600  1</span><br></pre></td></tr></table></figure><p>这里配置了多个 <code>save</code> 选项，当其中任意一个条件被满足时就会触发服务器执行 <code>BGSAVE</code> 命令。</p><blockquote><p>为了避免由于同时使用多个 <code>RDB</code> 文件创建方式或者配置多个 <code>save</code> 选项导致服务器频繁创建 <code>RDB</code> 文件，<code>Redis</code> 服务器在每次成功创建 <code>RDB</code> 文件后，会将负责自动触发 <code>BGSAVE</code> 命令的时间计数器以及修改次数计数器清零并重新开始计数。</p></blockquote><h4 id="SAVE-与-BGSAVE-的选择"><a href="#SAVE-与-BGSAVE-的选择" class="headerlink" title="SAVE 与 BGSAVE 的选择"></a>SAVE 与 BGSAVE 的选择</h4><p>由于 <code>SAVE</code> 命令会阻塞 <code>Redis</code> 服务器向其它客户端服务，所以如果我们需要创建 <code>RDB</code> 文件时同时为其它客户端服务，就只能使用 <code>BGSAVE</code> 命令创建 <code>RDB</code> 文件。</p><p>而 <code>SAVE</code> 命令更适合维护离线 <code>Redis</code> 服务器，因为它不会创建子进程而消耗额外的内存。</p><h3 id="RDB-优缺点"><a href="#RDB-优缺点" class="headerlink" title="RDB 优缺点"></a>RDB 优缺点</h3><p><code>RDB</code> 持久化可以生成紧凑的 <code>RDB</code> 文件，并且使用 <code>RDB</code>  文件恢复数据也很快.</p><p>但是无论是 <code>SAVE</code> 命令还是 <code>BGSAVE</code> 命令，当服务器停机时，服务器丢失的数据量取决于创建 <code>RDB</code> 文件的时间间隔：间隔越长，丢失数据越多。如果提高执行 <code>SAVE</code> 或者 <code>BGSAVE</code> 命令的频率，会导致 <code>Redis</code> 服务器性能骤降，甚至低于传统关系型数据库。</p><p>所以 <code>RDB</code> 持久化更像是一种备份手段而不是一种常规数据持久化方案。</p><h2 id="AOF-持久化"><a href="#AOF-持久化" class="headerlink" title="AOF 持久化"></a>AOF 持久化</h2><p><code>RDB</code> 持久化是全量式操作，而 <code>AOF</code> 是增量操作。</p><p>服务器每次执行完写命令之后，都会以<strong>协议文本</strong>的方式将被执行的写命令追加到 <code>AOF</code> 文件的结尾。在服务器停机之后，只需要重新执行 <code>AOF</code> 文件中保存的 <code>Redis</code> 命令，就可以将数据库恢复至停机之前的状态。</p><blockquote><p><code>AOF</code> 文件中唯一不是用户执行的命令是 <code>SELECT</code>，这是服务器根据用户正在使用的数据库号码自动加上的。</p></blockquote><p>同步命令到 AOF 文件的整个过程可以分为三个阶段：</p><ol><li>命令传播：<code>Redis</code> 将执行完的命令、命令的参数、命令的参数个数等信息发送到 <code>AOF</code> 程序中。</li><li>缓存追加：AOF 程序根据接收到的命令数据，<strong>将命令转换为网络通讯协议的格式</strong>，然后将协议内容追加到服务器的 AOF 缓存中。</li><li>文件写入和保存：AOF 缓存中的内容被写入到 <code>AOF</code> 文件末尾，如果设定的 <code>AOF</code> 保存条件被满足的话， <code>fsync</code> 函数或者 <code>fdatasync</code> 函数会被调用，将写入的内容真正地保存到磁盘中。</li></ol><p>由于默认持久化方式为 <code>RDB</code>，所以用户需要配置 <code>appendonly</code> 选项来打开 <code>AOF</code> 持久化功能：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendonly  yes</span><br></pre></td></tr></table></figure><p>打开 <code>AOF</code> 持久化功能之后，<code>Redis</code> 在默认情况下会创建一个名为 <code>appendonly.aof</code> 的文件作为 <code>AOF</code> 文件。</p><h3 id="AOF-文件冲洗频率"><a href="#AOF-文件冲洗频率" class="headerlink" title="AOF 文件冲洗频率"></a>AOF 文件冲洗频率</h3><blockquote><p>为了提高程序的写入性能，现代化的操作系统通常会把针对硬盘的多次写操作优化成一次写操作。当程序调用 <code>write</code> 系统调用对文件进行写入时，系统会先将数据写入位于内存的缓冲区中，当到达指定的时限或者满足某些写入条件时，系统才会调用 <code>fsync</code> 或者 <code>fdatasync</code> 函数，将缓冲区数据冲洗至硬盘。</p></blockquote><p>上述机制虽然能提高写入性能，但是对于持久化功能来说，两次执行冲洗操作的间隔会影响持久化的安全性。</p><p><code>Redis</code> 提供了 <code>appendfsync</code> 选项来控制系统冲洗 <code>AOF</code> 文件的频率。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">appendfsync  always|everysec|no</span><br></pre></td></tr></table></figure><p><code>appendfsync</code> 有三个可选值，分别代表的意义如下：</p><ul><li>always：每执行一个写命令，就对 <code>AOF</code> 文件执行一次冲洗操作</li><li>everysec：每隔 1s，就对 <code>AOF</code> 文件执行一次冲洗操作</li><li>no：不主动对  <code>AOF</code> 文件执行冲洗操作，由操作系统决定何时对 <code>AOF</code> 进行冲洗。</li></ul><p>对于这三种冲洗策略来说，不同的安全性对应着不同的性能：</p><ul><li>always：最多只会丢失一个命令的数据，但是由于对磁盘的频繁写入，导致 <code>Redis</code> 服务器性能骤降至关系型数据库的水平</li><li>everysec：最多丢失 1s 之内产生的命令数据，这是一种兼顾性能与安全性的折中方案</li><li>no：最多丢失服务器最后一次冲洗 <code>AOF</code> 文件之后产生的所有命令数据，数据量的大小取决于系统冲洗 <code>AOF</code> 文件的频率，不安全</li></ul><p>对比之下，<code>Redis</code> 选择 <code>everysec</code> 作为默认的冲洗策略，除非有明确的需求，否则也不应该修改该选项值。</p><h3 id="AOF-重写"><a href="#AOF-重写" class="headerlink" title="AOF 重写"></a>AOF 重写</h3><p>由于 <code>AOF</code> 的增量特性，<code>AOF</code> 文件会越来越大，其中也会存在一些对相同键执行过的多次修改操作，导致有一部分命令是冗余的。</p><p>例如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT 0</span><br><span class="line"></span><br><span class="line">SET  msg  &quot;hello world!&quot;</span><br><span class="line"></span><br><span class="line">SET  msg  &quot;good  bye&quot;</span><br></pre></td></tr></table></figure><p>实际上，上述三条命令可以直接将第二条去掉，执行后最终效果与原来是一致的。这种冗余命令的存在增加了 <code>AOF</code> 文件的体积，恢复数据时耗费时间也越多。</p><p>为了减少冗余命令，<code>Redis</code> 提供了 <code>AOF</code> 重写功能，该功能会能够生成一个全新的 <code>AOF</code> 文件，其中只包含恢复当前数据库所需要的尽可能少的命令。</p><p>对于上面的三条命令来说，<code>AOF</code> 重写之后就会变成如下所示：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">SELECT 0</span><br><span class="line"></span><br><span class="line">SET  msg  &quot;good  bye&quot;</span><br></pre></td></tr></table></figure><p> <code>AOF</code> 重写操作可以通过执行 <code>BGREWRITEAOF</code> 命令或者配置选项来触发。</p><h4 id="BGREWRITEAOF"><a href="#BGREWRITEAOF" class="headerlink" title="BGREWRITEAOF"></a>BGREWRITEAOF</h4><p><code>BGREWRITEAOF</code> 是一个无命令参数：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis&gt;  BGREWRITEAOF</span><br><span class="line">Background append only file rewriting started</span><br></pre></td></tr></table></figure><p>复杂度为 <code>O(N)</code>,<code>N</code> 表示服务器所有数据库包含的键值对总数。</p><p><code>BGREWRITEAOF</code> 是一个异步命令，<code>Redis</code> 服务器接收到该命令之后会创建一个子进程来扫描数据库并生成新的 <code>AOF</code> 文件。当新的 <code>AOF</code> 文件生成完毕，子进程就会退出并通知 <code>Redis</code>，<code>Redis</code> 就会使用新的 <code>AOF</code> 文件代替原有 <code>AOF</code> 文件。</p><p>如果发送 <code>BGREWRITEAOF</code> 请求时，服务器正在创建 <code>RDB</code> 文件，那么服务器会将 <code>AOF</code> 重写操作延后到 <code>RDB</code> 文件创建完毕之后再执行，避免两个写操作同时执行导致服务器性能下降。</p><p>如果服务器在执行重写操作的过程中，又收到了新的 <code>BGREWRITEAOF</code> 命令，那么会返回以下错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">redis&gt;  BGREWRITEAOF</span><br><span class="line">(error) ERR Background append only file rewriting already in progress</span><br></pre></td></tr></table></figure><h4 id="AOF-重写配置选项"><a href="#AOF-重写配置选项" class="headerlink" title="AOF 重写配置选项"></a>AOF 重写配置选项</h4><p>以下两个配置选项可以设置 <code>Redis</code> 触发 <code>BGREWRITEAOF</code> 命令的条件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">auto-aof-rewrite-min-size  &lt;value&gt;</span><br><span class="line">auto-aof-rewirte-percentage  &lt;value&gt;</span><br></pre></td></tr></table></figure><p><code>auto-aof-rewrite-min-size</code> 选项用于设置触发 <code>AOF</code> 重写所需要的最小 <code>AOF</code> 文件体积。</p><p>例如对于该选项默认值来说：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">auto-aof-rewrite-min-size  64mb</span><br></pre></td></tr></table></figure><p>当 <code>AOF</code> 文件体积小于 64mb 时，服务器不会自动执行 <code>BGREWRITEAOF</code> 命令。</p><p><code>auto-aof-rewirte-percentage</code> 选项配置的值是触发 <code>AOF</code> 重写所需要的文件体积增大比例。</p><p>例如对于该选项默认值来说：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">auto-aof-rewirte-percentage  100</span><br></pre></td></tr></table></figure><p>表示当前 <code>AOF</code> 文件体积比最后一次 <code>AOF</code> 文件重写之后的体积增大一倍时，会触发 <code>BGREWRITEAOF</code> 命令。</p><p>如果 <code>Redis</code> 还没有执行过 <code>AOF</code> 文件重写操作，那就会把启动服务器时使用的 <code>AOF</code> 文件体积当做最后一次 <code>AOF</code> 文件重写的体积。</p><p>假设 <code>AOF</code> 文件上次重写之后体积为 300MB，当前 <code>AOF</code> 文件达到 600MB 时,才会触发 <code>AOF</code> 重写操作。</p><h3 id="AOF-持久化优缺点"><a href="#AOF-持久化优缺点" class="headerlink" title="AOF 持久化优缺点"></a>AOF 持久化优缺点</h3><p><code>AOF</code> 持久化的安全性是 <code>RDB</code> 望尘莫及的，正常情况下配置 <code>appendonly everysec</code> 可以将数据丢失的时间压缩至 1s 以内。</p><p>当然，<code>AOF</code> 也有相应的缺点：</p><ul><li><code>AOF</code> 使用协议文本来存储操作,所以文件体积相对于包含相同数据的 <code>RDB</code> 文件来说会大得多，生成 <code>AOF</code> 文件所需的时间也比生成 <code>RDB</code> 文件时间更长</li><li><code>AOF</code> 持久化需要通过执行 <code>AOF</code> 文件中保存的命令来恢复数据库，所以 <code>AOF</code> 持久化数据恢复速度比 <code>RDB</code> 文件恢复慢很多，并且数据库体积越大，差距越明显</li><li><code>AOF</code> 使用的 <code>BGREWRITEAOF</code> 命令也需要创建子进程，如果数据库体积较大，进行 <code>AOF</code> 文件重写会占用大量资源，并导致服务器短暂阻塞。</li></ul><h2 id="RDB-AOF-混合持久化"><a href="#RDB-AOF-混合持久化" class="headerlink" title="RDB-AOF 混合持久化"></a>RDB-AOF 混合持久化</h2><p>由于 <code>RDB</code> 持久化与 <code>AOF</code> 持久化都有各自优缺点，用户也较难抉择。 <code>Redis4.0</code> 开始，引入了 <code>RDB-AOF</code> 混合持久化模式，这种模式基于 <code>AOF</code> 持久化模式构建。所以需要用户打开 <code>AOF</code> 持久化功能，并且配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aof-use-rdb-preamble  yes</span><br></pre></td></tr></table></figure><p>此后，当 <code>Redis</code> 执行 <code>AOF</code> 重写操作时，会根据数据库当前的状态生成出对应的 <code>RDB</code> 数据，并且将这部分数据写入新建的 <code>AOF</code> 文件当中，而在此之后执行的写操作，会以协议文本的方式追加到新的 <code>AOF</code> 文件末尾（即 <code>RDB</code> 数据后）。</p><p>当支持 <code>RDB-AOF</code> 混合持久化模式的 <code>Redis</code> 服务器启动并载入 <code>AOF</code> 文件时，首先会检查 <code>AOF</code> 文件头部是否包含 <code>RDB</code> 格式的内容。如果包含，那服务器就会先载入 <code>RDB</code> 数据，之后再载入 <code>AOF</code> 数据。</p><p><code>RDB-AOF</code> 混合持久化综合了 <code>RDB</code> 持久化与 <code>AOF</code> 持久化的优点。既可以通过 <code>AOF</code> 文件中的 <code>RDB</code> 数据快速恢复数据，又可以通过 <code>AOF</code> 包含的 <code>AOF</code> 数据将丢失数据的时间压缩至 1s 之内。</p><p><code>Redis</code>  现在已发布 5.0 版本，默认是没有打开 <code>RDB-AOF</code> 混合持久化功能的。不过 <code>Redis</code> 作者声称该持久化方式之后会取代 <code>RDB</code>  持久化成为 <code>Redis</code> 默认持久化方式。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;Redis&lt;/code&gt; 是一种内存型数据库，一旦服务器进程退出，数据库的数据就会丢失。为了解决这个问题，&lt;code&gt;Redis&lt;/code&gt; 提供了 &lt;code&gt;RDB&lt;/code&gt; 持久化、&lt;code&gt;AOF&lt;/code&gt; 持久化、&lt;code&gt;RDB-AOF&lt;/code&gt; 混合持久化等多种持久化方式，将内存中的数据保存到磁盘中，避免数据的丢失。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="http://changleamazing.com/categories/Redis/"/>
    
    
      <category term="Redis" scheme="http://changleamazing.com/tags/Redis/"/>
    
      <category term="Data Persistence" scheme="http://changleamazing.com/tags/Data-Persistence/"/>
    
  </entry>
  
  <entry>
    <title>HashMap 源码解析</title>
    <link href="http://changleamazing.com/2019/12/12/HashMap/"/>
    <id>http://changleamazing.com/2019/12/12/HashMap/</id>
    <published>2019-12-11T16:52:50.000Z</published>
    <updated>2020-04-20T19:40:05.581Z</updated>
    
    <content type="html"><![CDATA[<p>本文基于 <code>JDK8</code> 源码深入分析 <code>HashMap</code> 的结构与重要操作，并梳理一些面试中的常见问题。</p><a id="more"></a><h2 id="类结构"><a href="#类结构" class="headerlink" title="类结构"></a>类结构</h2><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://changleamazing-1253815386.cos.ap-guangzhou.myqcloud.com/2019/06/06/15597572496204.png" alt="" title="">                </div>                <div class="image-caption"></div>            </figure><h2 id="成员变量"><a href="#成员变量" class="headerlink" title="成员变量"></a>成员变量</h2><h3 id="DEFAULT-INITIAL-CAPACITY"><a href="#DEFAULT-INITIAL-CAPACITY" class="headerlink" title="DEFAULT_INITIAL_CAPACITY"></a>DEFAULT_INITIAL_CAPACITY</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_INITIAL_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">4</span>;</span><br></pre></td></tr></table></figure><p>HashMap 中槽数量的默认值，即 HashMap 中 table 数组的 <code>table.length</code>;</p><p>HashMap 初始化时，如果未指定 <code>capacity</code> 时，即设定 <code>capacity</code> 为此值。</p><h3 id="MAXIMUM-CAPACITY"><a href="#MAXIMUM-CAPACITY" class="headerlink" title="MAXIMUM_CAPACITY"></a>MAXIMUM_CAPACITY</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAXIMUM_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">30</span>;</span><br></pre></td></tr></table></figure><p>HashMap 中槽数量的最大值。</p><p>HashMap 初始化时，如果指定的 <code>capacity</code> 大于该值，则将 <code>capacity</code> 设置为该值。</p><h3 id="table"><a href="#table" class="headerlink" title="table"></a>table</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">transient</span> Node&lt;K,V&gt;[] table;</span><br></pre></td></tr></table></figure><p>HashMap 中装载数据的桶的数组。<code>table.length</code> 在分配数据之后长度总是 2 的幂。（除了在自举机制中一些操作允许长度为 0）</p><h3 id="entrySet"><a href="#entrySet" class="headerlink" title="entrySet"></a>entrySet</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">transient</span> Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;</span><br></pre></td></tr></table></figure><p>装载了所有键值对的集合，在遍历 HashMap 时一般使用这个集合，比使用 keySet 集合遍历速度大约快 1 倍。</p><h3 id="size"><a href="#size" class="headerlink" title="size"></a>size</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> size;</span><br></pre></td></tr></table></figure><p>HashMap 中目前存放的键值对的个数。</p><h3 id="modCount"><a href="#modCount" class="headerlink" title="modCount"></a>modCount</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> modCount;</span><br></pre></td></tr></table></figure><p>HashMap 结构更改的次数（即增删操作的次数）。用于在遍历时保证<code>fail-fast</code> 机制生效。</p><h3 id="threshold"><a href="#threshold" class="headerlink" title="threshold"></a>threshold</h3><p>HashMap 中存放键值对的阈值，当 <code>size &gt; threshold</code> 时，会触发 <code>table</code> 数组扩容操作。 </p><p><code>table</code> 数组没有被分配数据时，<code>threshold</code> 值等于 0 或者是 <code>table.length</code>。而在 <code>table</code> 数组被分配数据之后，它的值等于 <code>table.length * loadFactor</code>。</p><h3 id="loadFactor"><a href="#loadFactor" class="headerlink" title="loadFactor"></a>loadFactor</h3><p>装载因子：即负载率；默认为 <code>0.75</code>。</p><p>JDK 1.7 中提到，</p><blockquote><p>As a general rule, the default load factor (.75) offers a good tradeoff between time and space costs. Higher values decrease the space overhead but increase the lookup cost (reflected in most of the operations of the HashMap class, including get and put). The expected number of entries in the map and its load factor should be taken into account when setting its initial capacity, so as to minimize the number of rehash operations. If the initial capacity is greater than the maximum number of entries divided by the load factor, no rehash operations will ever occur.</p></blockquote><p>意思是 <code>0.75</code> 在时间和空间上提供了很好的折中。由于 <code>threshold = capacity * loadFactor</code> ，如果 <code>loadFactor</code> 设置过高，可以节省少量空间，但是会导致 <code>threshold</code> 和 <code>capacity</code> 非常接近， <code>Hash 碰撞</code> 的概率增大，一定程度上提高了 <code>put</code> 和 <code>get</code> 操作的耗时；如果 <code>loadFactor</code> 设置过低，则会产生相反的效果。</p><h3 id="TREEIFY-THRESHOLD"><a href="#TREEIFY-THRESHOLD" class="headerlink" title="TREEIFY_THRESHOLD"></a>TREEIFY_THRESHOLD</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TREEIFY_THRESHOLD = <span class="number">8</span>;</span><br></pre></td></tr></table></figure><p><code>table</code>数组中的每个槽中存储的数据量，在 <strong>大于</strong> 该值时，槽中存储数据的数据结构会变为红黑树。</p><p>###　UNTREEIFY_THRESHOLD</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> UNTREEIFY_THRESHOLD = <span class="number">6</span>;</span><br></pre></td></tr></table></figure><p>table`数组中的每个槽中存储的数据量，在 <strong>小于</strong> 该值时，槽中存储数据的数据结构会变为链表。</p><h2 id="构造方法"><a href="#构造方法" class="headerlink" title="构造方法"></a>构造方法</h2><h3 id="public-HashMap"><a href="#public-HashMap" class="headerlink" title="public HashMap()"></a>public HashMap()</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.loadFactor = DEFAULT_LOAD_FACTOR; <span class="comment">// all other fields defaulted</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最常用的构造方法。</p><p><code>loadFactor</code> 为默认值 0.75 ; </p><h3 id="public-HashMap-int-initialCapacity"><a href="#public-HashMap-int-initialCapacity" class="headerlink" title="public HashMap(int initialCapacity)"></a>public HashMap(int initialCapacity)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</span><br><span class="line">       <span class="keyword">this</span>(initialCapacity, DEFAULT_LOAD_FACTOR);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>调用 <code>public HashMap(int initialCapacity, float loadFactor);</code></p><p>手动设置 HashMap 的初始化容量。</p><p><code>loadFactor</code> 为默认值 0.75 ; </p><h3 id="public-HashMap-int-initialCapacity-float-loadFactor"><a href="#public-HashMap-int-initialCapacity-float-loadFactor" class="headerlink" title="public HashMap(int initialCapacity, float loadFactor)"></a>public HashMap(int initialCapacity, float loadFactor)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (initialCapacity &lt; <span class="number">0</span>)</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal initial capacity: "</span> +</span><br><span class="line">                                           initialCapacity);</span><br><span class="line">    <span class="keyword">if</span> (initialCapacity &gt; MAXIMUM_CAPACITY)</span><br><span class="line">        initialCapacity = MAXIMUM_CAPACITY;</span><br><span class="line">    <span class="keyword">if</span> (loadFactor &lt;= <span class="number">0</span> || Float.isNaN(loadFactor))</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal load factor: "</span> +</span><br><span class="line">                                           loadFactor);</span><br><span class="line">    <span class="keyword">this</span>.loadFactor = loadFactor;</span><br><span class="line">    <span class="keyword">this</span>.threshold = tableSizeFor(initialCapacity);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>loadFactor</code> 为自定义值 ; </p><h4 id="static-final-int-tableSizeFor-int-cap"><a href="#static-final-int-tableSizeFor-int-cap" class="headerlink" title="static final int tableSizeFor(int cap)"></a>static final int tableSizeFor(int cap)</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Returns a power of two size for the given target capacity.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">tableSizeFor</span><span class="params">(<span class="keyword">int</span> cap)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> n = cap - <span class="number">1</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">2</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">4</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">8</span>;</span><br><span class="line">    n |= n &gt;&gt;&gt; <span class="number">16</span>;</span><br><span class="line">    <span class="keyword">return</span> (n &lt; <span class="number">0</span>) ? <span class="number">1</span> : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从注释可知，该方法的返回值为 2 的幂。</p><p>实际上这个算法返回的是，大于 cap 的最接近 cap 的 2 的 次幂。</p><p>该构造方法，实际上控制的是 <code>threshold</code> 而不是直接设置 <code>capacity</code>。</p><h3 id="public-HashMap-Map-lt-extends-K-extends-V-gt-m"><a href="#public-HashMap-Map-lt-extends-K-extends-V-gt-m" class="headerlink" title="public HashMap(Map&lt;? extends K, ? extends V&gt; m)"></a>public HashMap(Map&lt;? extends K, ? extends V&gt; m)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(Map&lt;? extends K, ? extends V&gt; m)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">this</span>.loadFactor = DEFAULT_LOAD_FACTOR;</span><br><span class="line">    putMapEntries(m, <span class="keyword">false</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>用另一个 map 构造一个新的 hashmap。</p><p><code>loadFactor</code> 为默认值。</p><h4 id="final-void-putMapEntries-Map-lt-extends-K-extends-V-gt-m-boolean-evict"><a href="#final-void-putMapEntries-Map-lt-extends-K-extends-V-gt-m-boolean-evict" class="headerlink" title="final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict)"></a>final void putMapEntries(Map&lt;? extends K, ? extends V&gt; m, boolean evict)</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** 若 evict 为 false,代表是在创建 hashMap 时调用了这个函数;若 evict　为true,代表是在创建 hashMap 后才调用这个函数，例如 putAll 函数。*/</span></span><br><span class="line"><span class="function"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title">putMapEntries</span><span class="params">(Map&lt;? extends K, ? extends V&gt; m, <span class="keyword">boolean</span> evict)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> s = m.size();</span><br><span class="line">    <span class="keyword">if</span> (s &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">if</span> (table == <span class="keyword">null</span>) &#123; <span class="comment">// pre-size</span></span><br><span class="line">            <span class="keyword">float</span> ft = ((<span class="keyword">float</span>)s / loadFactor) + <span class="number">1.0F</span>;<span class="comment">// 阿里推荐初始化值</span></span><br><span class="line">            <span class="keyword">int</span> t = ((ft &lt; (<span class="keyword">float</span>)MAXIMUM_CAPACITY) ?</span><br><span class="line">                     (<span class="keyword">int</span>)ft : MAXIMUM_CAPACITY);</span><br><span class="line">            <span class="keyword">if</span> (t &gt; threshold)</span><br><span class="line">                threshold = tableSizeFor(t);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (s &gt; threshold)</span><br><span class="line">            resize();</span><br><span class="line">        <span class="keyword">for</span> (Map.Entry&lt;? extends K, ? extends V&gt; e : m.entrySet()) &#123;</span><br><span class="line">            K key = e.getKey();</span><br><span class="line">            V value = e.getValue();</span><br><span class="line">            putVal(hash(key), key, value, <span class="keyword">false</span>, evict);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>初始化时， <code>ft = ((float)s / loadFactor) + 1.0F</code>,即为 <code>table.length + 1</code>。然后调用 <code>threshold = tableSizeFor(t)</code>；这样 <code>threshold</code> 的值，是 <code>2 * table.length</code>。所以，新增元素不会立刻导致扩容。</p><h2 id="查"><a href="#查" class="headerlink" title="查"></a>查</h2><h3 id="public-V-get-Object-key"><a href="#public-V-get-Object-key" class="headerlink" title="public V get(Object key)"></a>public V get(Object key)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt; e;</span><br><span class="line">    <span class="keyword">return</span> (e = getNode(hash(key), key)) == <span class="keyword">null</span> ? <span class="keyword">null</span> : e.value;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="static-final-int-hash-Object-key"><a href="#static-final-int-hash-Object-key" class="headerlink" title="static final int hash(Object key)"></a>static final int hash(Object key)</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> h;</span><br><span class="line">    <span class="keyword">return</span> (key == <span class="keyword">null</span>) ? <span class="number">0</span> : (h = key.hashCode()) ^ (h &gt;&gt;&gt; <span class="number">16</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>该函数主要是调用了 <code>key.hashCode( )</code> 方法，实际就是 <code>Object</code> 类中的 <code>hashCode()</code> 方法。作用是将对象的地址映射成一个整数值，尽量保证随机性。<br>而 HashMap 中没有直接使用 <code>Object</code> 中的 <code>hashCode()</code> 的返回值作为 <code>hash()</code> 函数的结果，而是增加了 <code>(h = key.hashCode()) ^ (h &gt;&gt;&gt; 16)</code> 这一步,将 <code>hashCode()</code> 的返回值与向右移动 16 位的 h 做异或运算。这里，(h &gt;&gt;&gt; 16) 叫做 <strong>扰动函数</strong>，该扰动函数保证了函数最后的返回值的后十六位中，是高位与低位共同运算出的结果。增加了节点在 <code>table</code> 数组中分布的随机性。</p><blockquote><p>结果显示，当 <code>HashMap</code> 数组长度为 512 时，这个时候会取低 9 位的值来决定新增节点的位置。在有扰动函数的情况下，碰撞会减少 10%。</p></blockquote><h4 id="final-Node-lt-K-V-gt-getNode-int-hash-Object-key"><a href="#final-Node-lt-K-V-gt-getNode-int-hash-Object-key" class="headerlink" title="final Node&lt;K,V&gt; getNode(int hash, Object key)"></a>final Node&lt;K,V&gt; getNode(int hash, Object key)</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> Node&lt;K,V&gt; <span class="title">getNode</span><span class="params">(<span class="keyword">int</span> hash, Object key)</span> </span>&#123;</span><br><span class="line">       Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; <span class="keyword">int</span> n; K k;</span><br><span class="line">       <span class="comment">/* 条件判断，判断 `table` 数组不为空，且有元素存在；在该节点对应的槽里面也要有元素存在 */</span></span><br><span class="line">       <span class="keyword">if</span> ((tab = table) != <span class="keyword">null</span> &amp;&amp; (n = tab.length) &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">           (first = tab[(n - <span class="number">1</span>) &amp; hash]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">           <span class="comment">// 判断 key 是不是该槽位中的第一个元素。</span></span><br><span class="line">           <span class="keyword">if</span> (first.hash == hash &amp;&amp; <span class="comment">// always check first node</span></span><br><span class="line">               ((k = first.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">               <span class="keyword">return</span> first;</span><br><span class="line">           <span class="comment">// 如果该槽位中不止存在一个值，判断该槽位的节点是不是树节点    </span></span><br><span class="line">           <span class="keyword">if</span> ((e = first.next) != <span class="keyword">null</span>) &#123;</span><br><span class="line">               <span class="comment">//如果是树节点，直接调用树查找节点的方法。并返回查找到的值</span></span><br><span class="line">               <span class="keyword">if</span> (first <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                   <span class="keyword">return</span> ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);</span><br><span class="line">               <span class="comment">// 如果该槽位中的数据仍用链表存储。则直接遍历判断元素的 key 是不是等于要查找的 key</span></span><br><span class="line">               <span class="keyword">do</span> &#123;</span><br><span class="line">                   <span class="keyword">if</span> (e.hash == hash &amp;&amp;</span><br><span class="line">                       ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">                       <span class="keyword">return</span> e;</span><br><span class="line">               &#125; <span class="keyword">while</span> ((e = e.next) != <span class="keyword">null</span>);</span><br><span class="line">           &#125;</span><br><span class="line">       &#125;</span><br><span class="line">       <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>这是 HashMap 查找方法的主流程，相对比较简单。<br>在进行最外层判断时，使用到了 <code>tab[(n - 1) &amp; hash]</code> 这段代码。<br><code>tab[(n - 1) &amp; hash]</code> 是 <code>table.length</code> 必须保持 2 的 次幂的关键。<br>在得到一个元素 key 哈希运算返回值 <code>hash</code> 后，为了找到该元素在 <code>table</code> 中具体分布在哪个槽中，一般会使用 <code>hash % table.length</code>。<br><strong>当 <code>table.length</code> 等于 2^n 时， 存在<code>hash % table.length = hash &amp; (table.length - 1)</code></strong>。这样，由于位运算更快，可以更加快速的找到每一个节点对应的槽位。</p><h2 id="增-改"><a href="#增-改" class="headerlink" title="增/改"></a>增/改</h2><h3 id="public-V-put-K-key-V-value"><a href="#public-V-put-K-key-V-value" class="headerlink" title="public V put(K key, V value)"></a>public V put(K key, V value)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or</span></span><br><span class="line"><span class="comment">     *         &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;.</span></span><br><span class="line"><span class="comment">     *         (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map</span></span><br><span class="line"><span class="comment">     *         previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">    <span class="comment">//evict　为true,代表是在创建 hashMap 后才调用这个函数</span></span><br><span class="line">    <span class="comment">/** onlyIfAbsent 表示是否只在没有该节点映射时，put 才生效（是否允许覆盖）。</span></span><br><span class="line"><span class="comment">        false 表示允许覆盖操作 **/</span></span><br><span class="line">    <span class="keyword">return</span> putVal(hash(key), key, value, <span class="keyword">false</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果 HashMap 中已经存在该节点的映射（更新操作），返回值会是旧节点的 value。<br>如果不存在该节点的映射（新增操作），返回值会是 null。<br>所以<strong>可以用返回值来判断原来的 HashMap 中是否存在关于该节点的映射</strong>，在某些时刻很有用。</p><h4 id="final-V-putVal-int-hash-K-key-V-value-boolean-onlyIfAbsent-boolean-evict"><a href="#final-V-putVal-int-hash-K-key-V-value-boolean-onlyIfAbsent-boolean-evict" class="headerlink" title="final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict)"></a>final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict)</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> V <span class="title">putVal</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">boolean</span> onlyIfAbsent,</span></span></span><br><span class="line"><span class="function"><span class="params">                   <span class="keyword">boolean</span> evict)</span> </span>&#123;</span><br><span class="line">        Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; <span class="keyword">int</span> n, i;</span><br><span class="line">        <span class="comment">// 如果数组没有初始化，或者长度为 0，则重新设置数组长度</span></span><br><span class="line">        <span class="keyword">if</span> ((tab = table) == <span class="keyword">null</span> || (n = tab.length) == <span class="number">0</span>)</span><br><span class="line">            n = (tab = resize()).length;</span><br><span class="line">        <span class="comment">// 如果该节点 key 对应的槽位没有元素，直接新建节点将该元素放入该槽位</span></span><br><span class="line">        <span class="keyword">if</span> ((p = tab[i = (n - <span class="number">1</span>) &amp; hash]) == <span class="keyword">null</span>)</span><br><span class="line">            tab[i] = newNode(hash, key, value, <span class="keyword">null</span>);</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            Node&lt;K,V&gt; e; K k;</span><br><span class="line">            <span class="comment">/** 如果槽位的第一个元素 p 的 key 与 带插入的节点的 key 相等，则直接令 e = p，此时 e.value 被 p.value 替代，相当于更新操作 **/</span></span><br><span class="line">            <span class="keyword">if</span> (p.hash == hash &amp;&amp;</span><br><span class="line">                ((k = p.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">                e = p;</span><br><span class="line">            <span class="comment">/** 如果槽位的元素是树节点，调用树的插入值的方法</span></span><br><span class="line"><span class="comment">            else if (p instanceof TreeNode)</span></span><br><span class="line"><span class="comment">                e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value);</span></span><br><span class="line"><span class="comment">            // 槽中元素为链表节点</span></span><br><span class="line"><span class="comment">            else &#123;</span></span><br><span class="line"><span class="comment">                for (int binCount = 0; ; ++binCount) &#123;</span></span><br><span class="line"><span class="comment">                    // 判断 p 是否为尾结点</span></span><br><span class="line"><span class="comment">                    if ((e = p.next) == null) &#123;</span></span><br><span class="line"><span class="comment">                        p.next = newNode(hash, key, value, null);</span></span><br><span class="line"><span class="comment">                        // 判断新增节点后，是否需要更新数据结构，槽中节点数等于 8 就更新</span></span><br><span class="line"><span class="comment">                        if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st</span></span><br><span class="line"><span class="comment">                            treeifyBin(tab, hash);</span></span><br><span class="line"><span class="comment">                        break;</span></span><br><span class="line"><span class="comment">                    &#125;</span></span><br><span class="line"><span class="comment">                    //如果链表中有元素的 key 等于 e.key，则更新</span></span><br><span class="line"><span class="comment">                    if (e.hash == hash &amp;&amp;</span></span><br><span class="line"><span class="comment">                        ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))</span></span><br><span class="line"><span class="comment">                        break;</span></span><br><span class="line"><span class="comment">                    p = e;</span></span><br><span class="line"><span class="comment">                &#125;</span></span><br><span class="line"><span class="comment">            &#125;</span></span><br><span class="line"><span class="comment">            // 如果 e 不为 null，说明之前存在该 key 的映射，</span></span><br><span class="line"><span class="comment">            if (e != null) &#123; // existing mapping for key</span></span><br><span class="line"><span class="comment">                V oldValue = e.value;</span></span><br><span class="line"><span class="comment">                // 允许覆盖则更新节点值</span></span><br><span class="line"><span class="comment">                if (!onlyIfAbsent || oldValue == null)</span></span><br><span class="line"><span class="comment">                    e.value = value;</span></span><br><span class="line"><span class="comment">                // 为 linkedHashMap 提供的函数，将最近访问的元素置于链表尾部，保证链表有序性</span></span><br><span class="line"><span class="comment">                afterNodeAccess(e);</span></span><br><span class="line"><span class="comment">                return oldValue;</span></span><br><span class="line"><span class="comment">            &#125;</span></span><br><span class="line"><span class="comment">        &#125;</span></span><br><span class="line"><span class="comment">        // 修改次数增加</span></span><br><span class="line"><span class="comment">        ++modCount;</span></span><br><span class="line"><span class="comment">        // 判断是否需要扩容</span></span><br><span class="line"><span class="comment">        if (++size &gt; threshold)</span></span><br><span class="line"><span class="comment">            resize();</span></span><br><span class="line"><span class="comment">        // 为 linkedHashMap 提供的函数，回调删除头节点</span></span><br><span class="line"><span class="comment">        afterNodeInsertion(evict);</span></span><br><span class="line"><span class="comment">        return null;</span></span><br><span class="line"><span class="comment">    &#125;</span></span><br></pre></td></tr></table></figure><h3 id="public-V-putIfAbsent-K-key-V-value"><a href="#public-V-putIfAbsent-K-key-V-value" class="headerlink" title="public V putIfAbsent(K key, V value)"></a>public V putIfAbsent(K key, V value)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">putIfAbsent</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> putVal(hash(key), key, value, <span class="keyword">true</span>, <span class="keyword">true</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>第四个参数 <code>onlyIfAbsent</code> 为 true 表示只允许插入操作，更新操作不生效。</p><h2 id="删"><a href="#删" class="headerlink" title="删"></a>删</h2><h3 id="public-V-remove-Object-key"><a href="#public-V-remove-Object-key" class="headerlink" title="public V remove(Object key)"></a>public V remove(Object key)</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">remove</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">        Node&lt;K,V&gt; e;</span><br><span class="line">        <span class="keyword">return</span> (e = removeNode(hash(key), key, <span class="keyword">null</span>, <span class="keyword">false</span>, <span class="keyword">true</span>)) == <span class="keyword">null</span> ?</span><br><span class="line">            <span class="keyword">null</span> : e.value;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>如果返回值为空，表示 HashMap 中不存在该 key 对应的节点。否则，返回对应节点的 value。</p><h4 id="final-Node-lt-K-V-gt-removeNode-int-hash-Object-key-Object-value-boolean-matchValue-boolean-movable"><a href="#final-Node-lt-K-V-gt-removeNode-int-hash-Object-key-Object-value-boolean-matchValue-boolean-movable" class="headerlink" title="final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable)"></a>final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable)</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">final</span> Node&lt;K,V&gt; <span class="title">removeNode</span><span class="params">(<span class="keyword">int</span> hash, Object key, Object value,</span></span></span><br><span class="line"><span class="function"><span class="params">                               <span class="keyword">boolean</span> matchValue, <span class="keyword">boolean</span> movable)</span> </span>&#123;</span><br><span class="line">        Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; <span class="keyword">int</span> n, index;</span><br><span class="line">        <span class="comment">// 判断数组有元素存在且 key 对应的槽位有元素存在</span></span><br><span class="line">        <span class="keyword">if</span> ((tab = table) != <span class="keyword">null</span> &amp;&amp; (n = tab.length) &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">            (p = tab[index = (n - <span class="number">1</span>) &amp; hash]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">            Node&lt;K,V&gt; node = <span class="keyword">null</span>, e; K k; V v;</span><br><span class="line">            <span class="comment">// 如果槽中第一个元素 p 是要删除的节点，令 node = p</span></span><br><span class="line">            <span class="keyword">if</span> (p.hash == hash &amp;&amp;</span><br><span class="line">                ((k = p.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">                node = p;</span><br><span class="line">            <span class="comment">// 槽中第一个元素 p 不是要删除的节点，在后继节点中寻找</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((e = p.next) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">// 槽中元素存储在 RBT 中，令 node 等于从树中查找到的节点</span></span><br><span class="line">                <span class="keyword">if</span> (p <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                    node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key);</span><br><span class="line">                <span class="comment">// 槽中元素存储在链表中，令 node 等于从链表中查找到的节点</span></span><br><span class="line">                <span class="keyword">else</span> &#123;</span><br><span class="line">                    <span class="keyword">do</span> &#123;</span><br><span class="line">                        <span class="keyword">if</span> (e.hash == hash &amp;&amp;</span><br><span class="line">                            ((k = e.key) == key ||</span><br><span class="line">                             (key != <span class="keyword">null</span> &amp;&amp; key.equals(k)))) &#123;</span><br><span class="line">                            node = e;</span><br><span class="line">                            <span class="keyword">break</span>;</span><br><span class="line">                        &#125;</span><br><span class="line">                        p = e;</span><br><span class="line">                    &#125; <span class="keyword">while</span> ((e = e.next) != <span class="keyword">null</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// node 不为空, 且不需要匹配 value 或者成功匹配到 value，删除节点</span></span><br><span class="line">            <span class="keyword">if</span> (node != <span class="keyword">null</span> &amp;&amp; (!matchValue || (v = node.value) == value ||</span><br><span class="line">                                 (value != <span class="keyword">null</span> &amp;&amp; value.equals(v)))) &#123;</span><br><span class="line">                <span class="keyword">if</span> (node <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                    ((TreeNode&lt;K,V&gt;)node).removeTreeNode(<span class="keyword">this</span>, tab, movable);       </span><br><span class="line">                <span class="comment">// 如果要删除的节点为槽中第一个节点，则将第二个节点作为首节点</span></span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span> (node == p)</span><br><span class="line">                    tab[index] = node.next;</span><br><span class="line">                <span class="keyword">else</span></span><br><span class="line">                    p.next = node.next;</span><br><span class="line">                ++modCount;</span><br><span class="line">                --size;</span><br><span class="line">                afterNodeRemoval(node);</span><br><span class="line">                <span class="keyword">return</span> node;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="扩容"><a href="#扩容" class="headerlink" title="扩容"></a>扩容</h2><h3 id="final-Node-lt-K-V-gt-resize"><a href="#final-Node-lt-K-V-gt-resize" class="headerlink" title="final Node&lt;K,V&gt;[] resize()"></a>final Node&lt;K,V&gt;[] resize()</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> Node&lt;K,V&gt;[] resize() &#123;</span><br><span class="line">        Node&lt;K,V&gt;[] oldTab = table;</span><br><span class="line">        <span class="keyword">int</span> oldCap = (oldTab == <span class="keyword">null</span>) ? <span class="number">0</span> : oldTab.length;</span><br><span class="line">        <span class="keyword">int</span> oldThr = threshold;</span><br><span class="line">        <span class="keyword">int</span> newCap, newThr = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//如果数组已经初始化过且 table.length != 0</span></span><br><span class="line">        <span class="keyword">if</span> (oldCap &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">/** 如果数组原来的长度为 MAXIMUM_CAPACITY，table.length 无法扩大，</span></span><br><span class="line"><span class="comment">            修改 threshold = Integer.MAX_VALUE 使 map 可以继续存放元素</span></span><br><span class="line"><span class="comment">**/</span></span><br><span class="line">            <span class="keyword">if</span> (oldCap &gt;= MAXIMUM_CAPACITY) &#123;</span><br><span class="line">                threshold = Integer.MAX_VALUE;</span><br><span class="line">                <span class="keyword">return</span> oldTab;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 扩大 table.length = min(oldCap * 2 ,MAXIMUM_CAPACITY)</span></span><br><span class="line">            <span class="comment">//只有原来 oldCap.length &gt;= 16，会使阈值翻倍</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((newCap = oldCap &lt;&lt; <span class="number">1</span>) &lt; MAXIMUM_CAPACITY &amp;&amp;</span><br><span class="line">                     oldCap &gt;= DEFAULT_INITIAL_CAPACITY)</span><br><span class="line">                newThr = oldThr &lt;&lt; <span class="number">1</span>; <span class="comment">// double threshold</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//原来 table.length = 0 且 threshold ！= 0 ，在带参非集合初始化时会出现这种情况。</span></span><br><span class="line">        <span class="comment">//设置 newCap 为初始化时构造函数中 tableSizeFor() 方法返回的 threshold </span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (oldThr &gt; <span class="number">0</span>) <span class="comment">// initial capacity was placed in threshold    </span></span><br><span class="line">            newCap = oldThr;</span><br><span class="line">        <span class="comment">// table.length = 0 &amp;&amp; threshold = 0 ，无参初始化时出现这种情况</span></span><br><span class="line">        <span class="comment">// 设置 cap 和 threshold 为默认值</span></span><br><span class="line">        <span class="keyword">else</span> &#123;               <span class="comment">// zero initial threshold signifies using defaults</span></span><br><span class="line">            newCap = DEFAULT_INITIAL_CAPACITY;</span><br><span class="line">            newThr = (<span class="keyword">int</span>)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//有两种情况会符合该判断</span></span><br><span class="line">        <span class="comment">//1. 原来的 table.length * 2 &gt;= MAXIMUM_CAPACITY，</span></span><br><span class="line">        此时将 threshold 设置为 Integer.MAX_VALUE</span><br><span class="line">        <span class="comment">//2. 当原来的 table.length &lt; 16 时，设置 threshold = min(MAXIMUM_CAPACITY,threshold * loadFactor)。(故意设置 loadFactor 很高时，会出现 threshold * loadFactor &gt; MAXIMUM_CAPACITY)</span></span><br><span class="line">        <span class="keyword">if</span> (newThr == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">float</span> ft = (<span class="keyword">float</span>)newCap * loadFactor;</span><br><span class="line">            newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (<span class="keyword">float</span>)MAXIMUM_CAPACITY ?</span><br><span class="line">                      (<span class="keyword">int</span>)ft : Integer.MAX_VALUE);</span><br><span class="line">        &#125;</span><br><span class="line">        threshold = newThr;</span><br><span class="line">        <span class="meta">@SuppressWarnings</span>(&#123;<span class="string">"rawtypes"</span>,<span class="string">"unchecked"</span>&#125;)</span><br><span class="line">        Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])<span class="keyword">new</span> Node[newCap];</span><br><span class="line">        table = newTab;</span><br><span class="line">        <span class="keyword">if</span> (oldTab != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 移动元素</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; oldCap; ++j) &#123;</span><br><span class="line">                Node&lt;K,V&gt; e;</span><br><span class="line">                <span class="keyword">if</span> ((e = oldTab[j]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="comment">//方便 GC</span></span><br><span class="line">                    oldTab[j] = <span class="keyword">null</span>;</span><br><span class="line">                    <span class="comment">// 如果该槽中只有一个元素，新数组的槽中依然只有它一个元素</span></span><br><span class="line">                    <span class="keyword">if</span> (e.next == <span class="keyword">null</span>)</span><br><span class="line">                        newTab[e.hash &amp; (newCap - <span class="number">1</span>)] = e;</span><br><span class="line">                    <span class="comment">// 如果槽中数据结构为 RBT </span></span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span> (e <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                        ((TreeNode&lt;K,V&gt;)e).split(<span class="keyword">this</span>, newTab, j, oldCap);</span><br><span class="line">                    <span class="comment">// 如果槽中数据结构为链表</span></span><br><span class="line">                    <span class="keyword">else</span> &#123; <span class="comment">// preserve order</span></span><br><span class="line">                        <span class="comment">//</span></span><br><span class="line">                        Node&lt;K,V&gt; loHead = <span class="keyword">null</span>, loTail = <span class="keyword">null</span>;</span><br><span class="line">                        Node&lt;K,V&gt; hiHead = <span class="keyword">null</span>, hiTail = <span class="keyword">null</span>;</span><br><span class="line">                        Node&lt;K,V&gt; next;</span><br><span class="line">                        <span class="keyword">do</span> &#123;</span><br><span class="line">                            next = e.next;</span><br><span class="line">                            <span class="comment">// 确定该节点在 resize 之后是否会改变索引值</span></span><br><span class="line">                            <span class="comment">// e.hash &amp; oldCap = 0，说明索引值在 resize 之后不会改变</span></span><br><span class="line">                            <span class="keyword">if</span> ((e.hash &amp; oldCap) == <span class="number">0</span>) &#123;</span><br><span class="line">                                <span class="comment">//将元素放在索引为 index 的链表尾部</span></span><br><span class="line">                                <span class="keyword">if</span> (loTail == <span class="keyword">null</span>)</span><br><span class="line">                                    loHead = e;</span><br><span class="line">                                <span class="keyword">else</span></span><br><span class="line">                                <span class="comment">//这里说明了 JDK8 是尾插法    </span></span><br><span class="line">                                    loTail.next = e;</span><br><span class="line">                                loTail = e;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="keyword">else</span> &#123;</span><br><span class="line">                                 <span class="comment">//将元素放在索引为 index + oldCap 的链表尾部</span></span><br><span class="line">                                <span class="keyword">if</span> (hiTail == <span class="keyword">null</span>)</span><br><span class="line">                                    hiHead = e;</span><br><span class="line">                                <span class="keyword">else</span></span><br><span class="line">                                    hiTail.next = e;</span><br><span class="line">                                hiTail = e;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125; <span class="keyword">while</span> ((e = next) != <span class="keyword">null</span>);</span><br><span class="line">                        <span class="comment">//将链表尾结点置空</span></span><br><span class="line">                        <span class="keyword">if</span> (loTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                            loTail.next = <span class="keyword">null</span>;</span><br><span class="line">                            newTab[j] = loHead;</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">if</span> (hiTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                            hiTail.next = <span class="keyword">null</span>;</span><br><span class="line">                            newTab[j + oldCap] = hiHead;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> newTab;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>其中有一些很关键的点，</p><p>移动元素前会使判断 <code>e.hash &amp; oldCap</code> 是否等于 0。假设 <code>oldCap</code> 为 <code>2^k</code> ，元素<code>m</code> 的索引为 <code>oldIndex</code>，<code>hash(m)</code> 的值为 <code>hash</code>，存在 <code>oldIndex= hash &amp; ( 2^k - 1 )</code>。<strong>(2^k - 1) 的结果的二进制表达式是 k 个 1。所以 <code>oldIndex</code>的结果等于 <code>hash</code> 的二进制表达式的后 <code>k</code> 位的值。</strong></p><p>扩容后，新数组的长度 <code>newCap</code> 为 <code>2^(k + 1)</code>。元素 <code>m</code> 在新数组中的索引 <code>newIndex = hash &amp; (2 ^ (k + 1) - 1)</code>。同上，<code>newIndex</code> 的结果等于 <code>hash</code> 的二进制表达式的后 <code>k + 1</code> 位的值。用 <code>b</code> 代表 <code>hash</code>二进制表示的第<code>k + 1</code>位，那么 <code>newIndex - oldIndex</code> 就等于 <code>b</code> 代表的值。</p><p><code>b</code>的权值为 <code>2^k</code>等于 <code>oldCap</code>。当 <code>b = 0</code>时， <code>newIndex = oldIndex</code>；当 <code>b = 1</code>时，<code>newIndex = oldIndex + oldCap</code>。所以，元素<code>m</code>在新数组的位置就由<code>hash</code>的第 <code>k + 1</code>位的值确定，这个值就等于<code>hash &amp; oldCap</code>。</p><p>因此，我们在扩充 HashMap 的时候，不需要像 JDK1.7 的实现那样重新计算 hash 了。</p><p>另一个关键点，在于移动时，<strong>使用尾插法，保持了元素在原来槽中的相对顺序</strong>。这个方法，解决了 JDK1.7 中多线程访问 HashMap 时，<code>resize</code> 过程中会出现的循环链表的问题。<strong>但 HashMap 仍然不是线程安全的</strong>。</p><h2 id="重要问题"><a href="#重要问题" class="headerlink" title="重要问题"></a>重要问题</h2><h3 id="JDK8-相对于-JDK7-优化点有哪些"><a href="#JDK8-相对于-JDK7-优化点有哪些" class="headerlink" title="JDK8 相对于 JDK7 优化点有哪些"></a>JDK8 相对于 JDK7 优化点有哪些</h3><p>JDK8 对于 <code>HashMap</code> 的改动很大。主要的优化点在：</p><ol><li><code>HashMap</code> 中使用的数据结构新增红黑树，当哈希冲突严重时，查找元素的耗时也不会恶化到 O(n) 级别。</li><li>插入元素的方式。JDK8 采用了尾插法插入元素，在扩容时保持了原来元素的相对顺序。而 JDK7 采用的是头插法，多线程扩容时可能会导致产生闭环问题。</li><li>扩容时，<code>HashMap</code> 中元素索引直接由元素 <code>hashcode</code>来计算是原位置或者是原位置 + 数组长度。而在 JDK7 中，元素扩容时，都会调用 <code>hash()</code> 方法重新计算元素的 <code>hashcode</code> ，再决定元素在数组中的索引。</li></ol><h3 id="JDK1-7-死循环问题"><a href="#JDK1-7-死循环问题" class="headerlink" title="JDK1.7 死循环问题"></a>JDK1.7 死循环问题</h3><p>当多线程添加元素并且引起扩容时，可能会触发 <code>HashMap</code> 中某个链表死循环。主要的原因是 JDK1.7 使用的头插法，导致原来两个节点的顺序在扩容后被翻转，多线程操作时就可能引起死循环。而在 JDK1.8 中，扩容时使用的是尾插法插入元素，这样元素的相对顺序不会改变，所以不会再出现死循环的问题。</p><h3 id="JDK8-线程安全问题"><a href="#JDK8-线程安全问题" class="headerlink" title="JDK8 线程安全问题"></a>JDK8 线程安全问题</h3><p>JDK8 中解决了 <code>HashMap</code> 死循环之后，依然不是线程的。</p><p>举两个例子：</p><ol><li><p>当多线程放入两个 <code>hashcode</code> 一致的元素时，两个元素会放入相同的槽中，当他们获取到了同一个链表尾部元素时，会将各自的元素标记为链表尾部，导致其中一个元素丢失。</p></li><li><p>当多线程放入新元素时，都会执行到 <code>++size</code> 这一步，表示 <code>HashMap</code> 中保存的元素数量增加了，但是 <code>size</code> 并不是 <code>volatile</code> 修饰的，多线程操作时可能会导致值被覆盖，从而 <code>size</code> 与实际数据不对。</p></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本文基于 &lt;code&gt;JDK8&lt;/code&gt; 源码深入分析 &lt;code&gt;HashMap&lt;/code&gt; 的结构与重要操作，并梳理一些面试中的常见问题。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Java Collections" scheme="http://changleamazing.com/categories/Java-Collections/"/>
    
    
      <category term="HashMap" scheme="http://changleamazing.com/tags/HashMap/"/>
    
      <category term="Source Code" scheme="http://changleamazing.com/tags/Source-Code/"/>
    
  </entry>
  
  <entry>
    <title>Redis 分布式锁</title>
    <link href="http://changleamazing.com/2019/11/18/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/"/>
    <id>http://changleamazing.com/2019/11/18/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/</id>
    <published>2019-11-17T16:52:50.000Z</published>
    <updated>2020-04-20T19:41:16.577Z</updated>
    
    <content type="html"><![CDATA[<p>在单节点中，需要用并发线程都能访问到的资源的状态变化来控制同步。在分布式应用中，使用应用所有节点都能访问到的 <code>Redis</code> 中的某个 <code>key</code> 来控制多节点访问。</p><a id="more"></a><h2 id="单节点-Redis-分布式锁"><a href="#单节点-Redis-分布式锁" class="headerlink" title="单节点 Redis 分布式锁"></a>单节点 Redis 分布式锁</h2><h3 id="setnx"><a href="#setnx" class="headerlink" title="setnx"></a><code>setnx</code></h3><p><code>setnx</code> 指令会在 <code>key</code> 不存在的情况下放入 <code>redis</code>，如果存在则不会设置。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;setnx lock:distributed true</span><br><span class="line">OK</span><br><span class="line">...</span><br><span class="line">other code</span><br><span class="line">...</span><br><span class="line">&gt;del lock:distributed</span><br></pre></td></tr></table></figure><p>这种方式的问题在于，执行到 other code 时，程序出现异常，导致 <code>del</code> 指令不会被执行，<code>key</code> 没有被释放，这样会陷入死锁。</p><h3 id="setnx-then-expire"><a href="#setnx-then-expire" class="headerlink" title="setnx then expire"></a><code>setnx then expire</code></h3><p>为了解决死锁，乍一看可以使用 <code>expire</code> 来给 <code>key</code> 设置超时时间。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&gt;setnx lock:distributed true</span><br><span class="line">OK</span><br><span class="line">&gt;expire lock:distributed 5</span><br><span class="line">...</span><br><span class="line">other code</span><br><span class="line">...</span><br><span class="line">&gt;del lock:distributed</span><br></pre></td></tr></table></figure><p>这种处理其实仍然有问题，因为 <code>setnx</code> 与 <code>expire</code> 不是原子操作， 执行 <code>expire</code> 语句之前可能发生异常。死锁仍然会出现。</p><h3 id="set-and-expire"><a href="#set-and-expire" class="headerlink" title="set and expire"></a><code>set and expire</code></h3><p>为了解决非原子性操作被中断的问题，在 <code>Redis 2.8</code> 中加入了 <code>setnx</code> 与 <code>expire</code> 组合在一起的原子指令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;set lock:distributed true ex 5 nx</span><br><span class="line">OK</span><br><span class="line">...</span><br><span class="line">other code</span><br><span class="line">...</span><br><span class="line">&gt;del lock:distributed</span><br></pre></td></tr></table></figure><p>这种方式保证了加锁并设置有效时间操作的原子性，但是依然有问题。</p><p>假设我们在加锁与释放锁之间的业务代码执行时间超过了设置的有效时间，此时锁会因为超时被释放。会导致两种情况：</p><ol><li>其他节点 B 获取锁之后，执行超时节点 A 执行完成，释放了 B 的锁。</li><li>其它节点获取到了锁，执行临界区代码时就可能会出现并发问题。</li></ol><h3 id="解决锁被其他线程释放问题"><a href="#解决锁被其他线程释放问题" class="headerlink" title="解决锁被其他线程释放问题"></a>解决锁被其他线程释放问题</h3><p>因为在加锁时，各个节点使用的同一个 <code>key</code>，所以会存在超时节点释放了当前加锁节点的锁的情况。这种情况下，可以给加锁的 <code>key</code> 设置一个随机值，删除的时候需要判断 <code>key</code> 当前的 <code>value</code> 是不是等于随机值。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">val &#x3D; Random.nextInt();</span><br><span class="line">if( redis.set(key,val,true,5) )&#123;</span><br><span class="line">...</span><br><span class="line">other code</span><br><span class="line">...</span><br><span class="line">value &#x3D; redis.get(key);</span><br><span class="line">if(val &#x3D;&#x3D; value)&#123;</span><br><span class="line">redis.delete(key);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码实现了根据随机值删除的逻辑，但是获取 <code>value</code> 直到 <code>delete</code> 指令并非是原子指令，仍然可能有并发问题。这时候需要使用 <code>lua</code> 脚本处理，因为 <code>lua</code> 脚本可以保证连续多个指令原子执行。</p><figure class="highlight lua"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> redis.call(<span class="string">"get"</span>,KEYS[<span class="number">1</span>]) == ARGV[<span class="number">1</span>] <span class="keyword">then</span></span><br><span class="line">    <span class="keyword">return</span> redis.call(<span class="string">"del"</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>这种方式可以避免锁被其他线程释放的问题。</p><h3 id="临界区并发问题"><a href="#临界区并发问题" class="headerlink" title="临界区并发问题"></a>临界区并发问题</h3><p><strong>临界区代码出现并发问题的本质是业务代码执行时间大于锁过期时间。</strong></p><p>我们可以定时刷新加锁时间，保证业务代码在锁过期时间内执行完成。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">boolean</span> isFlushExpiration = <span class="keyword">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(redis.set(lock, val, NOT_EXIST, SECONDS, <span class="number">20</span>))&#123;</span><br><span class="line">    Thread thread = <span class="keyword">new</span> Thread(<span class="keyword">new</span> FlushExpirationTherad());</span><br><span class="line">thread.setDeamon(<span class="keyword">true</span>);</span><br><span class="line">  thread.start();</span><br><span class="line">    ...</span><br><span class="line">    other code</span><br><span class="line">    ... </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">isFlushExpiration = <span class="keyword">false</span>;</span><br><span class="line">String deleteScript = <span class="string">"if redis.call("</span>get<span class="string">",KEYS[1]) == ARGV[1] then"</span> </span><br><span class="line">    + <span class="string">"return redis.call("</span>del<span class="string">",KEYS[1])"</span></span><br><span class="line">    + <span class="string">"else return 0 end"</span>;</span><br><span class="line">redis.eval(deleteScript,<span class="number">1</span>,key,val);</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">FlushExpirationTherad</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(isFlushExpiration)&#123;</span><br><span class="line">            String checkAndExpireScript = <span class="string">"if redis.call('get', KEYS[1]) == ARGV[1] then "</span> +</span><br><span class="line">                        <span class="string">"return redis.call('expire',KEYS[1],ARGV[2]) "</span> +</span><br><span class="line">                        <span class="string">"else return 0 end"</span>;</span><br><span class="line">            redis.eval(checkAndExpireScript,<span class="number">1</span>,key,val,<span class="string">"20"</span>);</span><br><span class="line">            <span class="comment">// 每隔十秒检查是否完成</span></span><br><span class="line">            Thread.sleep(<span class="number">10</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这种实现是用一个线程定期监控客户端是否执行完成。也可以由服务端实现心跳检测机制来保证业务完成（<code>Zookeeper</code>)。</p><p>所以实现单节点 Redis 分布式锁要关注三个关键问题：</p><ol><li>获取锁与设置超时时间实现为原子操作（Redis2.8 开始已支持）</li><li>设置随机字符串保证释放锁时能保证只释放自己持有的锁（给对应的 key 设置随机值）</li><li>判断与释放锁必须实现为原子操作（lua 脚本实现）</li></ol><h2 id="多节点-Redis-分布式锁"><a href="#多节点-Redis-分布式锁" class="headerlink" title="多节点 Redis 分布式锁"></a>多节点 Redis 分布式锁</h2><p>为了保证项目的高可用性，项目一般都配置了 <code>Redis</code> 集群，以防在单节点 <code>Redis</code> 宕机之后，所有客户端都无法获得锁。</p><p>在集群环境下，<code>Redis</code> 存在 <code>failover</code> 机制。当 <code>Master</code> 节点宕机之后，会开始异步的主从复制（<code>replication</code>），这个过程可能会出现以下情况：</p><ol><li>客户端 A 获取了 <code>Master</code> 节点的锁。</li><li><code>Master</code> 节点宕机了，存储锁的 <code>key</code> 暂未同步到 <code>Slave</code> 上。</li><li><code>Slave</code> 节点升级为 <code>Master</code> 节点。</li><li>客户端 B 从新的 <code>Master</code> 节点上获取到了同一资源的锁。</li></ol><p>在这种情况下，锁的安全性就会被打破，<code>Redis</code> 作者 <code>antirez</code> 针对此问题设计了 <code>Redlock</code> 算法。</p><h3 id="Redlock-算法"><a href="#Redlock-算法" class="headerlink" title="Redlock 算法"></a>Redlock 算法</h3><p><code>Redlock</code> 算法获取锁时客户端执行步骤：</p><ol><li>获取当前时间（start）。</li><li>依次向 N 个 <code>Redis</code> 节点请求锁。请求锁的方式与从单节点 <code>Redis</code> 获取锁的方式一致。为了保证在某个 <code>Redis</code> 节点不可用时该算法能够继续运行，获取锁的操作都需要设置超时时间，需要保证该超时时间远小于锁的有效时间。这样才能保证客户端在向某个 <code>Redis</code> 节点获取锁失败之后，可以立刻尝试下一个节点。</li><li>计算获取锁的过程总共消耗多长时间（consumeTime = end - start）。如果客户端从大多数 <code>Redis</code> 节点（&gt;= N/2 + 1) 成功获取锁，并且获取锁总时长没有超过锁的有效时间，这种情况下，客户端会认为获取锁成功，否则，获取锁失败。</li><li>如果最终获取锁成功，锁的有效时间应该重新设置为锁最初的有效时间减去 <code>consumeTime</code>。</li><li>如果最终获取锁失败，客户端应该立刻向所有 <code>Redis</code> 节点发起释放锁的请求。</li></ol><p>在释放锁时，需要向<strong>所有 <code>Redis</code> 节点</strong>发起释放锁的操作，不管节点是否获取锁成功。因为可能存在客户端向 <code>Redis</code> 节点获取锁时成功，但节点通知客户端时通信失败，客户端会认为该节点加锁失败。</p><p><code>Redlock</code> 算法实现了更高的可用性，也不会出现 <code>failover</code> 时失效的问题。但是如果有节点崩溃重启，仍然对锁的安全性有影响。假设共有 5 个 <code>Redis</code> 节点 A、B、C、D、E：</p><ol><li>客户端 A 获取了 A、B、C 节点的锁，但 D 与 E 节点的锁获取失败。</li><li>节点 C 崩溃重启，但是客户端 A 在 C 上加的锁没有持久化下来，重启后丢失</li><li>节点 C 重启后，客户端 B 锁住了 C、D、E，获取锁成功。</li></ol><p>在这种情况下，客户端 A 与 B 都获取了访问同一资源的锁。</p><blockquote><p>这里第 2 步中节点 C 锁丢失的问题可能由多种原因引起。默认情况下，<code>Redis</code> 的 <code>AOF</code> 持久化方式是每秒写一次磁盘（fsync），这情况下就有可能丢失 1 秒的数据。我们也可以设置每次操作都触发 <code>fsync</code>，这会影响性能，不过即使这样设置，也有可能由于操作系统的问题导致操作写入失败。</p></blockquote><p>为了解决节点重启导致的锁失效问题，<code>antirez</code> 提出了延迟重启的概念，即当一个节点崩溃之后并不立即重启，而是等待与分布式锁相关的 <code>key</code> 的有效时间都过期之后再重启，这样在该节点重启后也不会对现有的锁造成影响。</p><h3 id="一些插曲"><a href="#一些插曲" class="headerlink" title="一些插曲"></a>一些插曲</h3><p>关于 <code>Redlock</code> 的安全性问题，在分布式系统专家 Martin Kleppmann 和 <code>Redis</code> 的作者 antirez 之间发生过一场争论，这个问题引发了激烈的讨论。关于这场争论的内容可以关注 <a href="http://zhangtielei.com/posts/blog-redlock-reasoning.html" target="_blank" rel="noopener">基于Redis的分布式锁到底安全吗</a> 这篇文章。<br>最后得出的结论是 <code>Redlock</code> 在效率要求的应用中是合理的，所以在 <code>Java</code> 项目中可以使用 <code>Redlock</code> 的 <code>Java</code> 版本 <code>Redission</code> 来控制多节点访问共享资源。但是仍有极端情况会造成 <code>Redlock</code> 的不安全，我们应该知道它在安全性上有哪些不足以及会造成什么后果。如果需要进一步的追求正确性，可以使用 <code>Zookeeper</code> 分布式锁。</p><h2 id="相关链接"><a href="#相关链接" class="headerlink" title="相关链接"></a>相关链接</h2><ul><li><a href="http://zhangtielei.com/posts/blog-redlock-reasoning-part2.html" target="_blank" rel="noopener">基于Redis的分布式锁到底安全吗</a></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在单节点中，需要用并发线程都能访问到的资源的状态变化来控制同步。在分布式应用中，使用应用所有节点都能访问到的 &lt;code&gt;Redis&lt;/code&gt; 中的某个 &lt;code&gt;key&lt;/code&gt; 来控制多节点访问。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Redis" scheme="http://changleamazing.com/categories/Redis/"/>
    
    
      <category term="Distributed Lock" scheme="http://changleamazing.com/tags/Distributed-Lock/"/>
    
      <category term="Redis" scheme="http://changleamazing.com/tags/Redis/"/>
    
      <category term="Distributed System" scheme="http://changleamazing.com/tags/Distributed-System/"/>
    
  </entry>
  
</feed>
